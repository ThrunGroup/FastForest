{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592af781",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5de16cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.datasets import *\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import copy\n",
    "\n",
    "from data_structures.tree_classifier import TreeClassifier\n",
    "import utils.utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a183e",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "331e630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function fetch_olivetti_faces at 0x7fb910b9f940>\n",
      "<function fetch_20newsgroups_vectorized at 0x7fb910b71e50>\n",
      "<function fetch_lfw_people at 0x7fb910af15e0>\n",
      "<function fetch_lfw_pairs at 0x7fb910af1700>\n",
      "<function fetch_covtype at 0x7fb910a9be50>\n",
      "<function fetch_rcv1 at 0x7fb9009f19d0>\n",
      "<function fetch_kddcup99 at 0x7fb910af1040>\n",
      "<function fetch_california_housing at 0x7fb9009f1820>\n"
     ]
    }
   ],
   "source": [
    "# Download all datasets from sklearn\n",
    "for m in [fetch_olivetti_faces, fetch_20newsgroups_vectorized, fetch_lfw_people, fetch_lfw_pairs, fetch_covtype, fetch_rcv1, fetch_kddcup99, fetch_california_housing]:\n",
    "    print(m)\n",
    "    try:\n",
    "        all_ = m()\n",
    "        train = m(subset='train')\n",
    "        test = m(subset='test')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dea93964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints:  1073\n",
      "Number of features:  18217\n",
      "Balance:  0.5526561043802423\n"
     ]
    }
   ],
   "source": [
    "# Download the data from two categories\n",
    "cats = ['alt.atheism', 'sci.space']\n",
    "ng_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "ng_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "trans = vectorizer.fit(ng_train.data)\n",
    "train_vectors = vectorizer.transform(ng_train.data)\n",
    "test_vectors = vectorizer.transform(ng_test.data)\n",
    "print(\"Number of datapoints: \", len(ng_train.data))\n",
    "print(\"Number of features: \", train_vectors.shape[1])\n",
    "print(\"Balance: \", np.sum(ng_train.target) / len(ng_train.target)) # 55-45, roughly balanced\n",
    "\n",
    "N_COMPONENTS=100\n",
    "pca = PCA(n_components=N_COMPONENTS)\n",
    "pca.fit(train_vectors.toarray())\n",
    "pca_train_vecs = pca.transform(train_vectors.toarray())\n",
    "pca_test_vecs = pca.transform(test_vectors.toarray())\n",
    "\n",
    "classes_arr = np.unique(ng_train.target)\n",
    "classes = utils.utils.class_to_idx(classes_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da9b97",
   "metadata": {},
   "source": [
    "# Compare our implementation's accuracy to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "983ecf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Decision Tree Accuracy: 0.7812061711079944\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(pca_train_vecs,ng_train.target)\n",
    "print(\"sklearn Decision Tree Accuracy:\", np.mean(dt.predict(pca_test_vecs) == ng_test.target))\n",
    "\n",
    "#cross_val_score(dt, pca_train_vecs, ng_train.target, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2554a668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Random Forest Accuracy: 0.8022440392706872\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(pca_train_vecs,ng_train.target)\n",
    "print(\"sklearn Random Forest Accuracy:\", np.mean(rf.predict(pca_test_vecs) == ng_test.target))\n",
    "\n",
    "#cross_val_score(rf, pca_train_vecs, ng_train.target, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a84470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8657968313140727\n",
      "Test accuracy: 0.7601683029453016\n",
      "Num queries: 7545\n",
      "Runtime: 8.689141988754272\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs, labels=ng_train.target, max_depth=5, classes=classes, verbose=False)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee840a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.869524697110904\n",
      "Test accuracy: 0.7938288920056101\n",
      "Num queries: 5300\n",
      "Runtime: 5.325762748718262\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs, labels=ng_train.target, max_depth=5, classes=classes, solver=\"EXACT\", verbose=False)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ffd149",
   "metadata": {},
   "source": [
    "# Make the dataset huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877237a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1073, 100)\n",
      "(17168, 100)\n"
     ]
    }
   ],
   "source": [
    "doublings = 4\n",
    "pca_train_vecs_huge = copy.deepcopy(pca_train_vecs)\n",
    "pca_train_labels_huge = copy.deepcopy(ng_train.target)\n",
    "print(pca_train_vecs_huge.shape)\n",
    "for i in range(doublings):\n",
    "    pca_train_vecs_huge = np.concatenate((pca_train_vecs_huge, pca_train_vecs_huge))\n",
    "    pca_train_labels_huge = np.concatenate((pca_train_labels_huge, pca_train_labels_huge))\n",
    "print(pca_train_vecs_huge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8eca539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated split with 100 queries\n",
      "Calculated split with 5300 queries\n",
      "Calculated split with 10800 queries\n",
      "Fitting finished\n",
      "Train accuracy: 0.8070829450139795\n",
      "Test accuracy: 0.761570827489481\n",
      "Num queries: 16200\n",
      "Runtime: 6.089082956314087\n",
      "|--- feature_1 <= -0.037112277192202114\n",
      "|   |--- feature_3 <= 0.11134765675972713\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_3 > 0.11134765675972713\n",
      "|   |   |--- class: 1\n",
      "|--- feature_1 > -0.037112277192202114\n",
      "|   |--- feature_3 <= -0.07697109870758101\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_3 > -0.07697109870758101\n",
      "|   |   |--- class: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs_huge, labels=pca_train_labels_huge, max_depth=2, classes=classes, verbose=True, random_state=0)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)\n",
    "tc.tree_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58f5a946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated split with 17168 queries\n",
      "Calculated split with 5728 queries\n",
      "Calculated split with 11440 queries\n",
      "Fitting finished\n",
      "Train accuracy: 0.8070829450139795\n",
      "Test accuracy: 0.761570827489481\n",
      "Num queries: 34336\n",
      "Runtime: 20.192893028259277\n",
      "|--- feature_1 <= -0.037112277192202114\n",
      "|   |--- feature_3 <= 0.11134765675972713\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_3 > 0.11134765675972713\n",
      "|   |   |--- class: 1\n",
      "|--- feature_1 > -0.037112277192202114\n",
      "|   |--- feature_3 <= -0.07697109870758101\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_3 > -0.07697109870758101\n",
      "|   |   |--- class: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We should implement vanilla TreeClassifier --> which uses identity bins\n",
    "\n",
    "tc = TreeClassifier(data=pca_train_vecs_huge, labels=pca_train_labels_huge, max_depth=2, classes=classes, solver=\"EXACT\", verbose=True, random_state=0)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)\n",
    "tc.tree_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec262c",
   "metadata": {},
   "source": [
    "# Verify our implementation of baseline models agrees with sklearn's in terms of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264ead3d",
   "metadata": {},
   "source": [
    "# Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f1d76ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_structures.wrappers.random_forest_classifier import RandomForestClassifier as RFC_ours\n",
    "from data_structures.wrappers.extremely_random_forest_classifier import ExtremelyRandomForestClassifier as ERFC_ours\n",
    "\n",
    "from data_structures.wrappers.random_forest_regressor import RandomForestRegressor as RFR_ours\n",
    "from data_structures.wrappers.extremely_random_forest_regressor import ExtremelyRandomForestRegressor as ERFR_ours\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC_sklearn\n",
    "from sklearn.bensemble import ExtraTreesClassifier as ERFC_sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR_sklearn\n",
    "from sklearn.ensemble import ExtraTreesRegressor as ERFR_sklearn\n",
    "\n",
    "from utils.constants import GINI, BEST, EXACT, MSE\n",
    "\n",
    "# TODO(@motiwari): Allow for gradient boosted comparisons as well\n",
    "def compare_accuracies(\n",
    "    compare: str = \"RFC\",\n",
    "    train_data: np.ndarray = None,\n",
    "    train_targets: np.ndarray = None,\n",
    "    test_data: np.ndarray = None,\n",
    "    test_targets: np.ndarray = None,\n",
    "    num_seeds: int = 10,\n",
    ") -> bool:\n",
    "    our_train_accs = []\n",
    "    our_test_accs = []\n",
    "    their_train_accs = []\n",
    "    their_test_accs = []\n",
    "    for seed in range(num_seeds):\n",
    "        # Ok to have n_jobs = -1 throughout?\n",
    "        if compare == \"RFC\":\n",
    "            our_model = RFC_ours(data=train_data, labels=train_labels, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = RFC_sklearn(n_estimators=5, criterion='gini', max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        elif compare == \"ERFC\":\n",
    "            our_model = ERFC_ours(data=train_data, labels=train_labels, n_estimators=5, max_depth=5, num_bins=None, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = ERFC_sklearn(n_estimators=5, criterion='gini', max_depth=5, min_samples_split=2, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=False, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        elif compare == \"RFR\":\n",
    "            our_model = RFR_ours(data=train_data, labels=train_labels, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=MSE, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = RFR_sklearn(n_estimators=5, criterion='squared_error', max_depth=5, min_samples_split=2, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, n_jobs=-1, random_state=seed, verbose=0)    \n",
    "        elif compare == \"ERFR\":\n",
    "            our_model = ERFR_ours(data=train_data, labels=train_labels, n_estimators=5, max_depth=5, num_bins=None, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=MSE, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = ERFR_sklearn(n_estimators=5, criterion='squared_error', max_depth=5, min_samples_split=2, max_features='auto', min_impurity_decrease=0.0, bootstrap=False, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Need to decide what models to compare\")\n",
    "        \n",
    "        our_model.fit()\n",
    "        their_model.fit(pca_train_vecs_huge, pca_train_labels_huge)\n",
    "\n",
    "        if compare == \"RFC\" or compare == \"ERFC\":\n",
    "            our_train_acc = np.mean(our_model.predict_batch(train_data)[0] == train_targets)\n",
    "            our_test_acc = np.mean(our_model.predict_batch(test_data)[0] == test_targets)\n",
    "            their_train_acc = np.mean(their_model.predict(train_data) == train_targets)\n",
    "            their_test_acc = np.mean(their_model.predict(test_data) == test_targets)\n",
    "        elif compare == \"RFR\" or compare == \"ERFR\":\n",
    "            our_train_acc = np.mean((our_model.predict_batch(train_data) - train_targets)**2)\n",
    "            our_test_acc = np.mean((our_model.predict_batch(test_data) - test_targets)**2)\n",
    "            their_train_acc = np.mean((our_model.predict_batch(train_data) - train_targets)**2)\n",
    "            their_test_acc = np.mean((our_model.predict_batch(test_data) - test_targets)**2)\n",
    "\n",
    "        print(\"(Ours) Train accuracy:\", our_train_acc)\n",
    "        print(\"(Ours) Test accuracy:\", our_test_acc)\n",
    "        print(\"(Theirs) Train accuracy:\", their_train_acc)\n",
    "        print(\"(Theirs) Test accuracy:\", their_test_acc)\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        our_train_accs.append(our_train_acc)\n",
    "        our_test_accs.append(our_test_acc)\n",
    "        their_train_accs.append(their_train_acc)\n",
    "        their_test_accs.append(their_test_acc)\n",
    "    \n",
    "    our_avg_train = np.mean(our_train_accs)\n",
    "    our_std_train = np.std(our_train_accs)\n",
    "\n",
    "    our_avg_test = np.mean(our_test_accs)\n",
    "    our_std_test = np.std(our_test_accs)\n",
    "    \n",
    "    their_avg_train = np.mean(their_train_accs)\n",
    "    their_std_train = np.std(their_train_accs)\n",
    "    \n",
    "    their_avg_test = np.mean(their_test_accs)\n",
    "    their_std_test = np.std(their_test_accs)\n",
    "    \n",
    "    # See if confidence intervals overlap\n",
    "    overlap = np.abs(their_avg_test - our_avg_test) < their_std_test + our_std_test\n",
    "    return overlap, our_avg_train, our_std_train, our_avg_test, our_std_test, their_avg_train, their_std_train, their_avg_test, their_std_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f79d3ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 0.8648648648648649\n",
      "(Ours) Test accuracy: 0.7896213183730715\n",
      "(Theirs) Train accuracy: 0.7931034482758621\n",
      "(Theirs) Test accuracy: 0.7475455820476858\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8704566635601119\n",
      "(Ours) Test accuracy: 0.7643758765778401\n",
      "(Theirs) Train accuracy: 0.8443616029822927\n",
      "(Theirs) Test accuracy: 0.7643758765778401\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.875116495806151\n",
      "(Ours) Test accuracy: 0.7601683029453016\n",
      "(Theirs) Train accuracy: 0.7996272134203168\n",
      "(Theirs) Test accuracy: 0.7545582047685835\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8564771668219944\n",
      "(Ours) Test accuracy: 0.726507713884993\n",
      "(Theirs) Train accuracy: 0.8285181733457595\n",
      "(Theirs) Test accuracy: 0.7769985974754559\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8499534016775396\n",
      "(Ours) Test accuracy: 0.729312762973352\n",
      "(Theirs) Train accuracy: 0.8387698042870456\n",
      "(Theirs) Test accuracy: 0.7629733520336606\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8732525629077353\n",
      "(Ours) Test accuracy: 0.7699859747545582\n",
      "(Theirs) Train accuracy: 0.7865796831314072\n",
      "(Theirs) Test accuracy: 0.7405329593267882\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.869524697110904\n",
      "(Ours) Test accuracy: 0.7699859747545582\n",
      "(Theirs) Train accuracy: 0.8070829450139795\n",
      "(Theirs) Test accuracy: 0.7489481065918654\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8835041938490215\n",
      "(Ours) Test accuracy: 0.7517531556802244\n",
      "(Theirs) Train accuracy: 0.8164026095060578\n",
      "(Theirs) Test accuracy: 0.7685834502103787\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8630009319664492\n",
      "(Ours) Test accuracy: 0.7517531556802244\n",
      "(Theirs) Train accuracy: 0.8331780055917987\n",
      "(Theirs) Test accuracy: 0.7699859747545582\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8536812674743709\n",
      "(Ours) Test accuracy: 0.7461430575035063\n",
      "(Theirs) Train accuracy: 0.8359739049394221\n",
      "(Theirs) Test accuracy: 0.7784011220196353\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 0.8659832246039143,\n",
       " 0.009922707663900228,\n",
       " 0.7559607293127629,\n",
       " 0.018232819074333793,\n",
       " 0.8183597390493942,\n",
       " 0.01963531888120251,\n",
       " 0.7612903225806451,\n",
       " 0.01223978918893207)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pca_train_vecs\n",
    "train_labels = ng_train.target\n",
    "test_data = pca_test_vecs\n",
    "test_labels = ng_test.target\n",
    "\n",
    "compare_accuracies(\"RFC\", train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ccd52dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 0.7185461323392358\n",
      "(Ours) Test accuracy: 0.6367461430575035\n",
      "(Theirs) Train accuracy: 0.777260018639329\n",
      "(Theirs) Test accuracy: 0.7307152875175316\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7315936626281454\n",
      "(Ours) Test accuracy: 0.638148667601683\n",
      "(Theirs) Train accuracy: 0.700838769804287\n",
      "(Theirs) Test accuracy: 0.6900420757363254\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7073625349487418\n",
      "(Ours) Test accuracy: 0.5974754558204769\n",
      "(Theirs) Train accuracy: 0.7092264678471575\n",
      "(Theirs) Test accuracy: 0.6774193548387096\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7073625349487418\n",
      "(Ours) Test accuracy: 0.6199158485273493\n",
      "(Theirs) Train accuracy: 0.6952469711090401\n",
      "(Theirs) Test accuracy: 0.6605890603085554\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.700838769804287\n",
      "(Ours) Test accuracy: 0.6255259467040674\n",
      "(Theirs) Train accuracy: 0.6421248835041938\n",
      "(Theirs) Test accuracy: 0.6143057503506312\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6598322460391426\n",
      "(Ours) Test accuracy: 0.5806451612903226\n",
      "(Theirs) Train accuracy: 0.7735321528424977\n",
      "(Theirs) Test accuracy: 0.7363253856942497\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7204100652376515\n",
      "(Ours) Test accuracy: 0.6185133239831697\n",
      "(Theirs) Train accuracy: 0.7157502329916123\n",
      "(Theirs) Test accuracy: 0.6661991584852734\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7325256290773532\n",
      "(Ours) Test accuracy: 0.6311360448807855\n",
      "(Theirs) Train accuracy: 0.6626281453867661\n",
      "(Theirs) Test accuracy: 0.6241234221598878\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6877912395153775\n",
      "(Ours) Test accuracy: 0.6129032258064516\n",
      "(Theirs) Train accuracy: 0.6309412861136999\n",
      "(Theirs) Test accuracy: 0.6100981767180925\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.723205964585275\n",
      "(Ours) Test accuracy: 0.6143057503506312\n",
      "(Theirs) Train accuracy: 0.6458527493010252\n",
      "(Theirs) Test accuracy: 0.5960729312762973\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 0.7089468779123951,\n",
       " 0.0210387168543773,\n",
       " 0.6175315568022441,\n",
       " 0.016865904357043132,\n",
       " 0.6953401677539609,\n",
       " 0.048951665274391376,\n",
       " 0.6605890603085554,\n",
       " 0.04692487467869127)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_accuracies(\"ERFC\", train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a81cc33",
   "metadata": {},
   "source": [
    "# Regression: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2065315",
   "metadata": {},
   "source": [
    "### Weirdly, we get exactly the same results as sklearn for all seeds. We should investigate whether this is a bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "96c4cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "data, targets = fetch_california_housing(return_X_y=True)\n",
    "random_idcs = np.random.choice(len(data), size=len(data),replace=False)\n",
    "data = data[random_idcs]\n",
    "targets = targets[random_idcs]\n",
    "\n",
    "TRAIN_TEST_SPLIT = 16000\n",
    "train_data = data[:TRAIN_TEST_SPLIT]\n",
    "train_targets = targets[:TRAIN_TEST_SPLIT]\n",
    "\n",
    "test_data = data[TRAIN_TEST_SPLIT:]\n",
    "test_targets = targets[TRAIN_TEST_SPLIT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "edf5a291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 3.6047103904415625\n",
      "(Ours) Test accuracy: 3.557280888823238\n",
      "(Theirs) Train accuracy: 3.6047103904415625\n",
      "(Theirs) Test accuracy: 3.557280888823238\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.698837202030057\n",
      "(Ours) Test accuracy: 3.649268394695702\n",
      "(Theirs) Train accuracy: 3.698837202030057\n",
      "(Theirs) Test accuracy: 3.649268394695702\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.668971394724753\n",
      "(Ours) Test accuracy: 3.6183697080805217\n",
      "(Theirs) Train accuracy: 3.668971394724753\n",
      "(Theirs) Test accuracy: 3.6183697080805217\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.732563296199221\n",
      "(Ours) Test accuracy: 3.6927617072229575\n",
      "(Theirs) Train accuracy: 3.732563296199221\n",
      "(Theirs) Test accuracy: 3.6927617072229575\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.6404918646836975\n",
      "(Ours) Test accuracy: 3.5838844263183107\n",
      "(Theirs) Train accuracy: 3.6404918646836975\n",
      "(Theirs) Test accuracy: 3.5838844263183107\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.7002097059375263\n",
      "(Ours) Test accuracy: 3.6597779091016633\n",
      "(Theirs) Train accuracy: 3.7002097059375263\n",
      "(Theirs) Test accuracy: 3.6597779091016633\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.699778863740869\n",
      "(Ours) Test accuracy: 3.655273057156532\n",
      "(Theirs) Train accuracy: 3.699778863740869\n",
      "(Theirs) Test accuracy: 3.655273057156532\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.623706505587273\n",
      "(Ours) Test accuracy: 3.5789843417925864\n",
      "(Theirs) Train accuracy: 3.623706505587273\n",
      "(Theirs) Test accuracy: 3.5789843417925864\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.6881967242030806\n",
      "(Ours) Test accuracy: 3.6531228056174094\n",
      "(Theirs) Train accuracy: 3.6881967242030806\n",
      "(Theirs) Test accuracy: 3.6531228056174094\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.7069903356899165\n",
      "(Ours) Test accuracy: 3.6714719110569587\n",
      "(Theirs) Train accuracy: 3.7069903356899165\n",
      "(Theirs) Test accuracy: 3.6714719110569587\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 3.6764456283237954,\n",
       " 0.038867352099088585,\n",
       " 3.632019514986588,\n",
       " 0.04266395398168999,\n",
       " 3.6764456283237954,\n",
       " 0.038867352099088585,\n",
       " 3.632019514986588,\n",
       " 0.04266395398168999)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_accuracies(\"RFR\", train_data, train_targets, test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "159edac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 3.6815378247519694\n",
      "(Ours) Test accuracy: 3.6407684028645155\n",
      "(Theirs) Train accuracy: 3.6815378247519694\n",
      "(Theirs) Test accuracy: 3.6407684028645155\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.6383368678729986\n",
      "(Ours) Test accuracy: 3.5958683000240095\n",
      "(Theirs) Train accuracy: 3.6383368678729986\n",
      "(Theirs) Test accuracy: 3.5958683000240095\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.6733018758052713\n",
      "(Ours) Test accuracy: 3.627187867032216\n",
      "(Theirs) Train accuracy: 3.6733018758052713\n",
      "(Theirs) Test accuracy: 3.627187867032216\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.6589668229880212\n",
      "(Ours) Test accuracy: 3.618059136379204\n",
      "(Theirs) Train accuracy: 3.6589668229880212\n",
      "(Theirs) Test accuracy: 3.618059136379204\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.6114095412271663\n",
      "(Ours) Test accuracy: 3.565551845832376\n",
      "(Theirs) Train accuracy: 3.6114095412271663\n",
      "(Theirs) Test accuracy: 3.565551845832376\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.648421266895394\n",
      "(Ours) Test accuracy: 3.6014246937725845\n",
      "(Theirs) Train accuracy: 3.648421266895394\n",
      "(Theirs) Test accuracy: 3.6014246937725845\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.6509283715398855\n",
      "(Ours) Test accuracy: 3.603530757223838\n",
      "(Theirs) Train accuracy: 3.6509283715398855\n",
      "(Theirs) Test accuracy: 3.603530757223838\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.672630745362043\n",
      "(Ours) Test accuracy: 3.631583607857939\n",
      "(Theirs) Train accuracy: 3.672630745362043\n",
      "(Theirs) Test accuracy: 3.631583607857939\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.675686089020523\n",
      "(Ours) Test accuracy: 3.6294174485388777\n",
      "(Theirs) Train accuracy: 3.675686089020523\n",
      "(Theirs) Test accuracy: 3.6294174485388777\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.673290229243686\n",
      "(Ours) Test accuracy: 3.6355368760700597\n",
      "(Theirs) Train accuracy: 3.673290229243686\n",
      "(Theirs) Test accuracy: 3.6355368760700597\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 3.6584509634706954,\n",
       " 0.020607753150392236,\n",
       " 3.6148928935595626,\n",
       " 0.022030467087038482,\n",
       " 3.6584509634706954,\n",
       " 0.020607753150392236,\n",
       " 3.6148928935595626,\n",
       " 0.022030467087038482)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_accuracies(\"ERFR\", train_data, train_targets, test_data, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1778e64",
   "metadata": {},
   "source": [
    "# Verify MAB solvers are faster in speed but have no change in accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbf3b00",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45303872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Any, Tuple\n",
    "\n",
    "# Classification #\n",
    "# Vanilla random forest + H + GB + GBH\n",
    "from data_structures.wrappers.random_forest_classifier import RandomForestClassifier as RFC\n",
    "from data_structures.wrappers.histogram_random_forest_classifier import HistogramRandomForestClassifier as HRFC\n",
    "from data_structures.wrappers.gradient_boosted_random_forest_classifier import GradientBoostedRandomForestClassifier as GBRFC\n",
    "from data_structures.wrappers.gradient_boosted_histogram_random_forest_classifier import GradientBoostedHistogramRandomForestClassifier as GBHRFC\n",
    "\n",
    "# Extremely random forest + GB (already histogrammed)\n",
    "from data_structures.wrappers.extremely_random_forest_classifier import ExtremelyRandomForestClassifier as ERFC\n",
    "from data_structures.wrappers.gradient_boosted_extremely_random_forest_classifier import GradientBoostedExtremelyRandomForestClassifier as GBERFC\n",
    "\n",
    "# Random patches + H + GB + GBH\n",
    "from data_structures.wrappers.random_patches_classifier import RandomPatchesClassifier as RPC\n",
    "from data_structures.wrappers.histogram_random_patches_classifier import HistogramRandomPatchesClassifier as HRPC\n",
    "from data_structures.wrappers.gradient_boosted_random_patches_classifier import GradientBoostedRandomPatchesClassifier as GBRPC\n",
    "from data_structures.wrappers.histogram_random_patches_classifier import HistogramRandomPatchesClassifier as HBRPC\n",
    "\n",
    "\n",
    "# Regression #\n",
    "# Vanilla random forest + H + GB + GBH\n",
    "from data_structures.wrappers.random_forest_regressor import RandomForestRegressor as RFR\n",
    "from data_structures.wrappers.histogram_random_forest_regressor import HistogramRandomForestRegressor as HRFR\n",
    "from data_structures.wrappers.gradient_boosted_random_forest_regressor import GradientBoostedRandomForestRegressor as GBRFR\n",
    "from data_structures.wrappers.gradient_boosted_histogram_random_forest_regressor import GradientBoostedHistogramRandomForestRegressor as GBHRFR\n",
    "\n",
    "# Extremely random forest + GB (already histogrammed)\n",
    "from data_structures.wrappers.extremely_random_forest_regressor import ExtremelyRandomForestRegressor as ERFR\n",
    "from data_structures.wrappers.gradient_boosted_extremely_random_forest_regressor import GradientBoostedExtremelyRandomForestRegressor as GBERFR\n",
    "\n",
    "# Random patches + H + GB + GBH\n",
    "from data_structures.wrappers.random_patches_regressor import RandomPatchesRegressor as RPR\n",
    "from data_structures.wrappers.histogram_random_patches_regressor import HistogramRandomPatchesRegressor as HRPR\n",
    "from data_structures.wrappers.gradient_boosted_random_patches_regressor import GradientBoostedRandomPatchesRegressor as GBRPR\n",
    "from data_structures.wrappers.histogram_random_patches_regressor import HistogramRandomPatchesRegressor as HBRPR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cad9875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def check_both_or_neither(\n",
    "    train_data: np.ndarray = None,\n",
    "    train_labels: np.ndarray = None,\n",
    ")    \n",
    "\n",
    "def time_measured_fit(\n",
    "    model: Any,\n",
    "    data: np.ndarray = None,\n",
    "    labels: np.ndarray = None,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Returns wall clock time of training the model, in seconds.\n",
    "    \n",
    "    Has a side effect: trains the model.\n",
    "    \"\"\"\n",
    "    assert (data is None and labels is None) or (data is not None and labels is not None), \"Need to pass both data and labels at the same time\"\n",
    "    \n",
    "    if data is None:\n",
    "        start = time.time()\n",
    "        model.fit()\n",
    "        end = time.time\n",
    "    else:\n",
    "        start = time.time()\n",
    "        model.fit(data, labels)\n",
    "        end = time.time\n",
    "    \n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3511c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_runtimes(\n",
    "    compare: str = \"RFC\",\n",
    "    train_data: np.ndarray = None,\n",
    "    train_targets: np.ndarray = None,\n",
    "    test_data: np.ndarray = None,\n",
    "    test_targets: np.ndarray = None,\n",
    "    num_seeds: int = 10,\n",
    ") -> bool:\n",
    "    # Runtimes\n",
    "    our_train_times = []\n",
    "    their_train_times = []\n",
    "    \n",
    "    # For accuracies\n",
    "    our_train_accs = []\n",
    "    our_test_accs = []\n",
    "    their_train_accs = []\n",
    "    their_test_accs = []\n",
    "    for seed in range(num_seeds):\n",
    "        # Ok to have n_jobs = -1 throughout?\n",
    "        if compare == \"RFC\":\n",
    "            our_model = RFC_ours(data=train_data, labels=train_labels, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = RFC_sklearn(n_estimators=5, criterion='gini', max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        elif compare == \"ERFC\":\n",
    "            our_model = ERFC_ours(data=train_data, labels=train_labels, n_estimators=5, max_depth=5, num_bins=None, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = ERFC_sklearn(n_estimators=5, criterion='gini', max_depth=5, min_samples_split=2, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=False, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        elif compare == \"RFR\":\n",
    "            our_model = RFR_ours(data=train_data, labels=train_labels, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=MSE, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = RFR_sklearn(n_estimators=5, criterion='squared_error', max_depth=5, min_samples_split=2, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, n_jobs=-1, random_state=seed, verbose=0)    \n",
    "        elif compare == \"ERFR\":\n",
    "            our_model = ERFR_ours(data=train_data, labels=train_labels, n_estimators=5, max_depth=5, num_bins=None, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=MSE, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = ERFR_sklearn(n_estimators=5, criterion='squared_error', max_depth=5, min_samples_split=2, max_features='auto', min_impurity_decrease=0.0, bootstrap=False, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Need to decide what models to compare\")\n",
    "        \n",
    "        assert 'sklearn' not in their_model.__module__, \"Cannot use sklearn models for runtime comparisons\"\n",
    "        \n",
    "        our_runtime = time_measured_fit(our_model)\n",
    "        their_runtime = time_measured_fit(their_model, train_data, train_labels)\n",
    "\n",
    "        if compare == \"RFC\" or compare == \"ERFC\":\n",
    "            our_train_acc = np.mean(our_model.predict_batch(train_data)[0] == train_targets)\n",
    "            our_test_acc = np.mean(our_model.predict_batch(test_data)[0] == test_targets)\n",
    "            their_train_acc = np.mean(their_model.predict(train_data) == train_targets)\n",
    "            their_test_acc = np.mean(their_model.predict(test_data) == test_targets)\n",
    "        elif compare == \"RFR\" or compare == \"ERFR\":\n",
    "            our_train_acc = np.mean((our_model.predict_batch(train_data) - train_targets)**2)\n",
    "            our_test_acc = np.mean((our_model.predict_batch(test_data) - test_targets)**2)\n",
    "            their_train_acc = np.mean((our_model.predict_batch(train_data) - train_targets)**2)\n",
    "            their_test_acc = np.mean((our_model.predict_batch(test_data) - test_targets)**2)\n",
    "\n",
    "        print(\"(Ours) Train accuracy:\", our_train_acc)\n",
    "        print(\"(Ours) Test accuracy:\", our_test_acc)\n",
    "        print(\"(Theirs) Train accuracy:\", their_train_acc)\n",
    "        print(\"(Theirs) Test accuracy:\", their_test_acc)\n",
    "        print(\"*\" * 30)\n",
    "        print(\"(Ours) Runtime:\", our_train_time)\n",
    "        print(\"(Theirs) Runtime:\", their_train_time)\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        our_train_accs.append(our_train_acc)\n",
    "        our_test_accs.append(our_test_acc)\n",
    "        their_train_accs.append(their_train_acc)\n",
    "        their_test_accs.append(their_test_acc)\n",
    "    \n",
    "    # For accuracies\n",
    "    our_avg_train = np.mean(our_train_accs)\n",
    "    our_std_train = np.std(our_train_accs)\n",
    "\n",
    "    our_avg_test = np.mean(our_test_accs)\n",
    "    our_std_test = np.std(our_test_accs)\n",
    "    \n",
    "    their_avg_train = np.mean(their_train_accs)\n",
    "    their_std_train = np.std(their_train_accs)\n",
    "    \n",
    "    their_avg_test = np.mean(their_test_accs)\n",
    "    their_std_test = np.std(their_test_accs)\n",
    "    \n",
    "    # For runtimes\n",
    "    our_avg_train_time = np.mean(our_train_times)\n",
    "    our_std_train_time = np.std(our_train_times)\n",
    "    \n",
    "    their_avg_train_time = np.mean(their_train_times)\n",
    "    their_std_train_time = np.std(their_train_times)\n",
    "    \n",
    "    \n",
    "    # See if confidence intervals overlap\n",
    "    overlap = np.abs(their_avg_test - our_avg_test) < their_std_test + our_std_test\n",
    "    return overlap, our_avg_train, our_std_train, our_avg_test, our_std_test, their_avg_train, their_std_train, their_avg_test, their_std_test, our_avg_train_time, our_std_train_time, their_avg_train_time, their_std_train_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
