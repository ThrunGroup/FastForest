{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592af781",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5de16cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.datasets import *\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import copy\n",
    "\n",
    "from data_structures.tree_classifier import TreeClassifier\n",
    "import utils.utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a183e",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "331e630f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function fetch_olivetti_faces at 0x7fb910b9f940>\n",
      "<function fetch_20newsgroups_vectorized at 0x7fb910b71e50>\n",
      "<function fetch_lfw_people at 0x7fb910af15e0>\n",
      "<function fetch_lfw_pairs at 0x7fb910af1700>\n",
      "<function fetch_covtype at 0x7fb910a9be50>\n",
      "<function fetch_rcv1 at 0x7fb9009f19d0>\n",
      "<function fetch_kddcup99 at 0x7fb910af1040>\n",
      "<function fetch_california_housing at 0x7fb9009f1820>\n"
     ]
    }
   ],
   "source": [
    "# Download all datasets from sklearn\n",
    "for m in [fetch_olivetti_faces, fetch_20newsgroups_vectorized, fetch_lfw_people, fetch_lfw_pairs, fetch_covtype, fetch_rcv1, fetch_kddcup99, fetch_california_housing]:\n",
    "    print(m)\n",
    "    try:\n",
    "        all_ = m()\n",
    "        train = m(subset='train')\n",
    "        test = m(subset='test')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dea93964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints:  1073\n",
      "Number of features:  18217\n",
      "Balance:  0.5526561043802423\n"
     ]
    }
   ],
   "source": [
    "# Download the data from two categories\n",
    "cats = ['alt.atheism', 'sci.space']\n",
    "ng_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "ng_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "trans = vectorizer.fit(ng_train.data)\n",
    "train_vectors = vectorizer.transform(ng_train.data)\n",
    "test_vectors = vectorizer.transform(ng_test.data)\n",
    "print(\"Number of datapoints: \", len(ng_train.data))\n",
    "print(\"Number of features: \", train_vectors.shape[1])\n",
    "print(\"Balance: \", np.sum(ng_train.target) / len(ng_train.target)) # 55-45, roughly balanced\n",
    "\n",
    "N_COMPONENTS=100\n",
    "pca = PCA(n_components=N_COMPONENTS)\n",
    "pca.fit(train_vectors.toarray())\n",
    "pca_train_vecs = pca.transform(train_vectors.toarray())\n",
    "pca_test_vecs = pca.transform(test_vectors.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da9b97",
   "metadata": {},
   "source": [
    "# Compare our implementation's accuracy to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "983ecf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Decision Tree Accuracy: 0.7840112201963534\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(pca_train_vecs,ng_train.target)\n",
    "print(\"sklearn Decision Tree Accuracy:\", np.mean(dt.predict(pca_test_vecs) == ng_test.target))\n",
    "\n",
    "#cross_val_score(dt, pca_train_vecs, ng_train.target, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2554a668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Random Forest Accuracy: 0.7966339410939691\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(pca_train_vecs,ng_train.target)\n",
    "print(\"sklearn Random Forest Accuracy:\", np.mean(rf.predict(pca_test_vecs) == ng_test.target))\n",
    "\n",
    "#cross_val_score(rf, pca_train_vecs, ng_train.target, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e8bfc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_arr = np.unique(ng_train.target)\n",
    "classes = utils.utils.class_to_idx(classes_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a84470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8704566635601119\n",
      "Test accuracy: 0.7840112201963534\n",
      "Num queries: 7435\n",
      "Runtime: 7.624583005905151\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs, labels=ng_train.target, max_depth=5, classes=classes, verbose=False)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee840a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8713886300093197\n",
      "Test accuracy: 0.7840112201963534\n",
      "Num queries: 5294\n",
      "Runtime: 4.370760202407837\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs, labels=ng_train.target, max_depth=5, classes=classes, solver=\"EXACT\", verbose=False)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ffd149",
   "metadata": {},
   "source": [
    "# Make the dataset huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "877237a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1073, 100)\n",
      "(17168, 100)\n"
     ]
    }
   ],
   "source": [
    "doublings = 4\n",
    "pca_train_vecs_huge = copy.deepcopy(pca_train_vecs)\n",
    "pca_train_labels_huge = copy.deepcopy(ng_train.target)\n",
    "print(pca_train_vecs_huge.shape)\n",
    "for i in range(doublings):\n",
    "    pca_train_vecs_huge = np.concatenate((pca_train_vecs_huge, pca_train_vecs_huge))\n",
    "    pca_train_labels_huge = np.concatenate((pca_train_labels_huge, pca_train_labels_huge))\n",
    "print(pca_train_vecs_huge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8eca539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated split with 1900 queries\n",
      "Calculated split with 11428 queries\n",
      "Calculated split with 22840 queries\n",
      "Fitting finished\n",
      "Train accuracy: 0.8070829450139795\n",
      "Test accuracy: 0.761570827489481\n",
      "Num queries: 36168\n",
      "Runtime: 9.714073181152344\n",
      "|--- feature_1 <= -0.037112264624637015\n",
      "|   |--- feature_3 <= 0.11134642234670764\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_3 > 0.11134642234670764\n",
      "|   |   |--- class: 1\n",
      "|--- feature_1 > -0.037112264624637015\n",
      "|   |--- feature_3 <= -0.07697285483262639\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_3 > -0.07697285483262639\n",
      "|   |   |--- class: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs_huge, labels=pca_train_labels_huge, max_depth=2, classes=classes, verbose=True, random_state=0)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)\n",
    "tc.tree_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f5a946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated split with 17168 queries\n",
      "Calculated split with 5728 queries\n",
      "Calculated split with 11440 queries\n",
      "Fitting finished\n",
      "Train accuracy: 0.8070829450139795\n",
      "Test accuracy: 0.761570827489481\n",
      "Num queries: 34336\n",
      "Runtime: 18.33877205848694\n",
      "|--- feature_1 <= -0.037112264624637015\n",
      "|   |--- feature_3 <= 0.11134642234670764\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_3 > 0.11134642234670764\n",
      "|   |   |--- class: 1\n",
      "|--- feature_1 > -0.037112264624637015\n",
      "|   |--- feature_3 <= -0.07697285483262639\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_3 > -0.07697285483262639\n",
      "|   |   |--- class: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We should implement vanilla TreeClassifier --> which uses identity bins\n",
    "\n",
    "tc = TreeClassifier(data=pca_train_vecs_huge, labels=pca_train_labels_huge, max_depth=2, classes=classes, solver=\"EXACT\", verbose=True, random_state=0)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)\n",
    "tc.tree_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e65d67e",
   "metadata": {},
   "source": [
    "# Verify our implementation of RFC agrees with sklearn's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd42b7",
   "metadata": {},
   "source": [
    "# Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f8cb047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_structures.wrappers.random_forest_classifier import RandomForestClassifier as RFC_ours\n",
    "from data_structures.wrappers.extremely_random_forest_classifier import ExtremelyRandomForestClassifier as ERFC_ours\n",
    "\n",
    "from data_structures.wrappers.random_forest_regressor import RandomForestRegressor as RFR_ours\n",
    "from data_structures.wrappers.extremely_random_forest_regressor import ExtremelyRandomForestRegressor as ERFR_ours\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC_sklearn\n",
    "from sklearn.bensemble import ExtraTreesClassifier as ERFC_sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR_sklearn\n",
    "from sklearn.ensemble import ExtraTreesRegressor as ERFR_sklearn\n",
    "\n",
    "from utils.constants import GINI, BEST, EXACT, MSE\n",
    "\n",
    "# TODO(@motiwari): Allow for gradient boosted comparisons as well\n",
    "def compare_accuracies(\n",
    "    compare: str = \"RFC\",\n",
    "    train_data: np.ndarray = None,\n",
    "    train_targets: np.ndarray = None,\n",
    "    test_data: np.ndarray = None,\n",
    "    test_targets: np.ndarray = None,\n",
    "    num_seeds: int = 10,\n",
    ") -> bool:\n",
    "    our_train_accs = []\n",
    "    our_test_accs = []\n",
    "    their_train_accs = []\n",
    "    their_test_accs = []\n",
    "    for seed in range(num_seeds):\n",
    "        # Ok to have n_jobs = -1 throughout?\n",
    "        if compare == \"RFC\":\n",
    "            our_model = RFC_ours(data=train_data, labels=train_labels, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = RFC_sklearn(n_estimators=5, criterion='gini', max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        elif compare == \"ERFC\":\n",
    "            our_model = ERFC_ours(data=train_data, labels=train_labels, n_estimators=5, max_depth=5, num_bins=None, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = ERFC_sklearn(n_estimators=5, criterion='gini', max_depth=5, min_samples_split=2, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=False, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        elif compare == \"RFR\":\n",
    "            our_model = RFR_ours(data=train_data, labels=train_labels, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=MSE, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = RFR_sklearn(n_estimators=5, criterion='squared_error', max_depth=5, min_samples_split=2, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, n_jobs=-1, random_state=seed, verbose=0)    \n",
    "        elif compare == \"ERFR\":\n",
    "            our_model = ERFR_ours(data=train_data, labels=train_labels, n_estimators=5, max_depth=5, num_bins=None, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=MSE, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = ERFR_sklearn(n_estimators=5, criterion='squared_error', max_depth=5, min_samples_split=2, max_features='auto', min_impurity_decrease=0.0, bootstrap=False, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Need to decide what models to compare\")\n",
    "        \n",
    "        our_model.fit()\n",
    "        their_model.fit(pca_train_vecs_huge, pca_train_labels_huge)\n",
    "\n",
    "        if compare == \"RFC\" or compare == \"ERFC\":\n",
    "            our_train_acc = np.mean(our_model.predict_batch(train_data)[0] == train_targets)\n",
    "            our_test_acc = np.mean(our_model.predict_batch(test_data)[0] == test_targets)\n",
    "            their_train_acc = np.mean(their_model.predict(train_data) == train_targets)\n",
    "            their_test_acc = np.mean(their_model.predict(test_data) == test_targets)\n",
    "        elif compare == \"RFR\" or compare == \"ERFR\":\n",
    "            our_train_acc = np.mean((our_model.predict_batch(train_data) - train_targets)**2)\n",
    "            our_test_acc = np.mean((our_model.predict_batch(test_data) - test_targets)**2)\n",
    "            their_train_acc = np.mean((our_model.predict_batch(train_data) - train_targets)**2)\n",
    "            their_test_acc = np.mean((our_model.predict_batch(test_data) - test_targets)**2)\n",
    "\n",
    "        print(\"(Ours) Train accuracy:\", our_train_acc)\n",
    "        print(\"(Ours) Test accuracy:\", our_test_acc)\n",
    "        print(\"(Theirs) Train accuracy:\", their_train_acc)\n",
    "        print(\"(Theirs) Test accuracy:\", their_test_acc)\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        our_train_accs.append(our_train_acc)\n",
    "        our_test_accs.append(our_test_acc)\n",
    "        their_train_accs.append(their_train_acc)\n",
    "        their_test_accs.append(their_test_acc)\n",
    "    \n",
    "    our_avg_train = np.mean(our_train_accs)\n",
    "    our_std_train = np.std(our_train_accs)\n",
    "\n",
    "    our_avg_test = np.mean(our_test_accs)\n",
    "    our_std_test = np.std(our_test_accs)\n",
    "    \n",
    "    their_avg_train = np.mean(their_train_accs)\n",
    "    their_std_train = np.std(their_train_accs)\n",
    "    \n",
    "    their_avg_test = np.mean(their_test_accs)\n",
    "    their_std_test = np.std(their_test_accs)\n",
    "    \n",
    "    # See if confidence intervals overlap\n",
    "    overlap = np.abs(their_avg_test - our_avg_test) < their_std_test + our_std_test\n",
    "    return overlap, our_avg_train, our_std_train, our_avg_test, our_std_test, their_avg_train, their_std_train, their_avg_test, their_std_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "afb1565c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 0.8648648648648649\n",
      "(Ours) Test accuracy: 0.7896213183730715\n",
      "(Theirs) Train accuracy: 0.7931034482758621\n",
      "(Theirs) Test accuracy: 0.7475455820476858\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8704566635601119\n",
      "(Ours) Test accuracy: 0.7643758765778401\n",
      "(Theirs) Train accuracy: 0.8443616029822927\n",
      "(Theirs) Test accuracy: 0.7643758765778401\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.875116495806151\n",
      "(Ours) Test accuracy: 0.7601683029453016\n",
      "(Theirs) Train accuracy: 0.7996272134203168\n",
      "(Theirs) Test accuracy: 0.7545582047685835\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8564771668219944\n",
      "(Ours) Test accuracy: 0.726507713884993\n",
      "(Theirs) Train accuracy: 0.8285181733457595\n",
      "(Theirs) Test accuracy: 0.7769985974754559\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8499534016775396\n",
      "(Ours) Test accuracy: 0.729312762973352\n",
      "(Theirs) Train accuracy: 0.8387698042870456\n",
      "(Theirs) Test accuracy: 0.7629733520336606\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8732525629077353\n",
      "(Ours) Test accuracy: 0.7699859747545582\n",
      "(Theirs) Train accuracy: 0.7865796831314072\n",
      "(Theirs) Test accuracy: 0.7405329593267882\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.869524697110904\n",
      "(Ours) Test accuracy: 0.7699859747545582\n",
      "(Theirs) Train accuracy: 0.8070829450139795\n",
      "(Theirs) Test accuracy: 0.7489481065918654\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8835041938490215\n",
      "(Ours) Test accuracy: 0.7517531556802244\n",
      "(Theirs) Train accuracy: 0.8164026095060578\n",
      "(Theirs) Test accuracy: 0.7685834502103787\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8630009319664492\n",
      "(Ours) Test accuracy: 0.7517531556802244\n",
      "(Theirs) Train accuracy: 0.8331780055917987\n",
      "(Theirs) Test accuracy: 0.7699859747545582\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8536812674743709\n",
      "(Ours) Test accuracy: 0.7461430575035063\n",
      "(Theirs) Train accuracy: 0.8359739049394221\n",
      "(Theirs) Test accuracy: 0.7784011220196353\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 0.8659832246039143,\n",
       " 0.009922707663900228,\n",
       " 0.7559607293127629,\n",
       " 0.018232819074333793,\n",
       " 0.8183597390493942,\n",
       " 0.01963531888120251,\n",
       " 0.7612903225806451,\n",
       " 0.01223978918893207)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pca_train_vecs\n",
    "train_labels = ng_train.target\n",
    "test_data = pca_test_vecs\n",
    "test_labels = ng_test.target\n",
    "\n",
    "compare_accuracies(\"RFC\", train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d1c8b718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 0.7185461323392358\n",
      "(Ours) Test accuracy: 0.6367461430575035\n",
      "(Theirs) Train accuracy: 0.777260018639329\n",
      "(Theirs) Test accuracy: 0.7307152875175316\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7315936626281454\n",
      "(Ours) Test accuracy: 0.638148667601683\n",
      "(Theirs) Train accuracy: 0.700838769804287\n",
      "(Theirs) Test accuracy: 0.6900420757363254\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7073625349487418\n",
      "(Ours) Test accuracy: 0.5974754558204769\n",
      "(Theirs) Train accuracy: 0.7092264678471575\n",
      "(Theirs) Test accuracy: 0.6774193548387096\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7073625349487418\n",
      "(Ours) Test accuracy: 0.6199158485273493\n",
      "(Theirs) Train accuracy: 0.6952469711090401\n",
      "(Theirs) Test accuracy: 0.6605890603085554\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.700838769804287\n",
      "(Ours) Test accuracy: 0.6255259467040674\n",
      "(Theirs) Train accuracy: 0.6421248835041938\n",
      "(Theirs) Test accuracy: 0.6143057503506312\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6598322460391426\n",
      "(Ours) Test accuracy: 0.5806451612903226\n",
      "(Theirs) Train accuracy: 0.7735321528424977\n",
      "(Theirs) Test accuracy: 0.7363253856942497\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7204100652376515\n",
      "(Ours) Test accuracy: 0.6185133239831697\n",
      "(Theirs) Train accuracy: 0.7157502329916123\n",
      "(Theirs) Test accuracy: 0.6661991584852734\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7325256290773532\n",
      "(Ours) Test accuracy: 0.6311360448807855\n",
      "(Theirs) Train accuracy: 0.6626281453867661\n",
      "(Theirs) Test accuracy: 0.6241234221598878\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6877912395153775\n",
      "(Ours) Test accuracy: 0.6129032258064516\n",
      "(Theirs) Train accuracy: 0.6309412861136999\n",
      "(Theirs) Test accuracy: 0.6100981767180925\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.723205964585275\n",
      "(Ours) Test accuracy: 0.6143057503506312\n",
      "(Theirs) Train accuracy: 0.6458527493010252\n",
      "(Theirs) Test accuracy: 0.5960729312762973\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 0.7089468779123951,\n",
       " 0.0210387168543773,\n",
       " 0.6175315568022441,\n",
       " 0.016865904357043132,\n",
       " 0.6953401677539609,\n",
       " 0.048951665274391376,\n",
       " 0.6605890603085554,\n",
       " 0.04692487467869127)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_accuracies(\"ERFC\", train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6196998d",
   "metadata": {},
   "source": [
    "# Regression: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc95511",
   "metadata": {},
   "source": [
    "### Weirdly, we get exactly the same results as sklearn for all seeds. We should investigate whether this is a bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d6027c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "data, targets = fetch_california_housing(return_X_y=True)\n",
    "random_idcs = np.random.choice(len(data), size=len(data),replace=False)\n",
    "data = data[random_idcs]\n",
    "targets = targets[random_idcs]\n",
    "\n",
    "TRAIN_TEST_SPLIT = 16000\n",
    "train_data = data[:TRAIN_TEST_SPLIT]\n",
    "train_targets = targets[:TRAIN_TEST_SPLIT]\n",
    "\n",
    "test_data = data[TRAIN_TEST_SPLIT:]\n",
    "test_targets = targets[TRAIN_TEST_SPLIT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60eb5e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 3.6047103904415625\n",
      "(Ours) Test accuracy: 3.557280888823238\n",
      "(Theirs) Train accuracy: 3.6047103904415625\n",
      "(Theirs) Test accuracy: 3.557280888823238\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.698837202030057\n",
      "(Ours) Test accuracy: 3.649268394695702\n",
      "(Theirs) Train accuracy: 3.698837202030057\n",
      "(Theirs) Test accuracy: 3.649268394695702\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.668971394724753\n",
      "(Ours) Test accuracy: 3.6183697080805217\n",
      "(Theirs) Train accuracy: 3.668971394724753\n",
      "(Theirs) Test accuracy: 3.6183697080805217\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.732563296199221\n",
      "(Ours) Test accuracy: 3.6927617072229575\n",
      "(Theirs) Train accuracy: 3.732563296199221\n",
      "(Theirs) Test accuracy: 3.6927617072229575\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.6404918646836975\n",
      "(Ours) Test accuracy: 3.5838844263183107\n",
      "(Theirs) Train accuracy: 3.6404918646836975\n",
      "(Theirs) Test accuracy: 3.5838844263183107\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.7002097059375263\n",
      "(Ours) Test accuracy: 3.6597779091016633\n",
      "(Theirs) Train accuracy: 3.7002097059375263\n",
      "(Theirs) Test accuracy: 3.6597779091016633\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.699778863740869\n",
      "(Ours) Test accuracy: 3.655273057156532\n",
      "(Theirs) Train accuracy: 3.699778863740869\n",
      "(Theirs) Test accuracy: 3.655273057156532\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 3.623706505587273\n",
      "(Ours) Test accuracy: 3.5789843417925864\n",
      "(Theirs) Train accuracy: 3.623706505587273\n",
      "(Theirs) Test accuracy: 3.5789843417925864\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "compare_accuracies(\"RFR\", train_data, train_targets, test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5d41cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 0.21130813838301798\n",
      "(Ours) Test accuracy: 0.23171692519662102\n",
      "(Theirs) Train accuracy: 0.21130813838301798\n",
      "(Theirs) Test accuracy: 0.23171692519662102\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2z/dxb5rnhd7wx6yg77m3z4c1n40000gn/T/ipykernel_79181/1147426982.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_accuracies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ERFR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/2z/dxb5rnhd7wx6yg77m3z4c1n40000gn/T/ipykernel_79181/2394407698.py\u001b[0m in \u001b[0;36mcompare_accuracies\u001b[0;34m(compare, train_data, train_targets, test_data, test_targets, num_seeds)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Need to decide what models to compare\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mour_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mtheir_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca_train_vecs_huge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca_train_labels_huge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/RandomForest/data_structures/forest_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, labels)\u001b[0m\n\u001b[1;32m    189\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 )\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_boosting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0;31m# TODO: currently uses O(n) computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/RandomForest/data_structures/tree_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_budget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_budget\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                         \u001b[0;31m# Runs solve_mab if not previously computed, which incurs cost!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m                         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_best_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/RandomForest/data_structures/node.py\u001b[0m in \u001b[0;36mcalculate_best_split\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m             )\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEXACT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             results = solve_exactly(\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_idcs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/RandomForest/utils/solvers.py\u001b[0m in \u001b[0;36msolve_exactly\u001b[0;34m(data, labels, discrete_bins_dict, binning_type, num_bins, is_classification, impurity_measure, min_impurity_reduction)\u001b[0m\n\u001b[1;32m    129\u001b[0m     )\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     estimates[accesses], _cb_delta, num_queries, _ = sample_targets(\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mis_classification\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/RandomForest/utils/solvers.py\u001b[0m in \u001b[0;36msample_targets\u001b[0;34m(is_classification, data, labels, arms, histograms, batch_size, impurity_measure, population_idcs)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf2bin_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHistogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistograms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_labels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This is where the labels are used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;31m# TODO(@motiwari): Can make this more efficient because a lot of histogram computation is reused across steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         i_r, cb_d = get_impurity_reductions(\n",
      "\u001b[0;32m~/Desktop/RandomForest/data_structures/histogram.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_pile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mleft_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_pile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlinear_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compare_accuracies(\"ERFR\", train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270fad02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
