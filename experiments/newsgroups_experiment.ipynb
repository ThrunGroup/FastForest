{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592af781",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5de16cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.datasets import *\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import copy\n",
    "\n",
    "from data_structures.tree_classifier import TreeClassifier\n",
    "import utils.utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a183e",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all datasets from sklearn\n",
    "for m in [fetch_olivetti_faces, fetch_20newsgroups_vectorized, fetch_lfw_people, fetch_lfw_pairs, fetch_covtype, fetch_rcv1, fetch_kddcup99, fetch_california_housing]:\n",
    "    print(m)\n",
    "    try:\n",
    "        all_ = m()\n",
    "        train = m(subset='train')\n",
    "        test = m(subset='test')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea93964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints:  1073\n",
      "Number of features:  18217\n",
      "Balance:  0.5526561043802423\n"
     ]
    }
   ],
   "source": [
    "# Download the data from two categories\n",
    "cats = ['alt.atheism', 'sci.space']\n",
    "ng_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "ng_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "trans = vectorizer.fit(ng_train.data)\n",
    "train_vectors = vectorizer.transform(ng_train.data)\n",
    "test_vectors = vectorizer.transform(ng_test.data)\n",
    "print(\"Number of datapoints: \", len(ng_train.data))\n",
    "print(\"Number of features: \", train_vectors.shape[1])\n",
    "print(\"Balance: \", np.sum(ng_train.target) / len(ng_train.target)) # 55-45, roughly balanced\n",
    "\n",
    "N_COMPONENTS=100\n",
    "pca = PCA(n_components=N_COMPONENTS)\n",
    "pca.fit(train_vectors.toarray())\n",
    "pca_train_vecs = pca.transform(train_vectors.toarray())\n",
    "pca_test_vecs = pca.transform(test_vectors.toarray())\n",
    "\n",
    "classes_arr = np.unique(ng_train.target)\n",
    "classes = utils.utils.class_to_idx(classes_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da9b97",
   "metadata": {},
   "source": [
    "# Compare our implementation's accuracy to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "983ecf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Decision Tree Accuracy: 0.782608695652174\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(pca_train_vecs,ng_train.target)\n",
    "print(\"sklearn Decision Tree Accuracy:\", np.mean(dt.predict(pca_test_vecs) == ng_test.target))\n",
    "\n",
    "#cross_val_score(dt, pca_train_vecs, ng_train.target, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2554a668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Random Forest Accuracy: 0.8050490883590463\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(pca_train_vecs,ng_train.target)\n",
    "print(\"sklearn Random Forest Accuracy:\", np.mean(rf.predict(pca_test_vecs) == ng_test.target))\n",
    "\n",
    "#cross_val_score(rf, pca_train_vecs, ng_train.target, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a84470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8704566635601119\n",
      "Test accuracy: 0.7868162692847125\n",
      "Num queries: 4406\n",
      "Runtime: 6.60705304145813\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs, labels=ng_train.target, max_depth=5, classes=classes, verbose=False)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee840a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.8704566635601119\n",
      "Test accuracy: 0.7868162692847125\n",
      "Num queries: 5300\n",
      "Runtime: 5.1996259689331055\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs, labels=ng_train.target, max_depth=5, classes=classes, solver=\"EXACT\", verbose=False)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ffd149",
   "metadata": {},
   "source": [
    "# Make the dataset huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "877237a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1073, 100)\n",
      "(17168, 100)\n"
     ]
    }
   ],
   "source": [
    "doublings = 4\n",
    "pca_train_vecs_huge = copy.deepcopy(pca_train_vecs)\n",
    "pca_train_labels_huge = copy.deepcopy(ng_train.target)\n",
    "print(pca_train_vecs_huge.shape)\n",
    "for i in range(doublings):\n",
    "    pca_train_vecs_huge = np.concatenate((pca_train_vecs_huge, pca_train_vecs_huge))\n",
    "    pca_train_labels_huge = np.concatenate((pca_train_labels_huge, pca_train_labels_huge))\n",
    "print(pca_train_vecs_huge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8eca539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated split with 100 queries\n",
      "Calculated split with 5400 queries\n",
      "Calculated split with 10900 queries\n",
      "Fitting finished\n",
      "Train accuracy: 0.8070829450139795\n",
      "Test accuracy: 0.761570827489481\n",
      "Num queries: 16400\n",
      "Runtime: 6.1677350997924805\n",
      "|--- feature_1 <= -0.037112255696725716\n",
      "|   |--- feature_3 <= 0.11135085961226182\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_3 > 0.11135085961226182\n",
      "|   |   |--- class: 1\n",
      "|--- feature_1 > -0.037112255696725716\n",
      "|   |--- feature_3 <= -0.07696973751446881\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_3 > -0.07696973751446881\n",
      "|   |   |--- class: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs_huge, labels=pca_train_labels_huge, max_depth=2, classes=classes, verbose=True, random_state=0)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)\n",
    "tc.tree_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58f5a946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated split with 17168 queries\n",
      "Calculated split with 5728 queries\n",
      "Calculated split with 11440 queries\n",
      "Fitting finished\n",
      "Train accuracy: 0.8070829450139795\n",
      "Test accuracy: 0.761570827489481\n",
      "Num queries: 34336\n",
      "Runtime: 22.784740209579468\n",
      "|--- feature_1 <= -0.037112255696725716\n",
      "|   |--- feature_3 <= 0.11135085961226182\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_3 > 0.11135085961226182\n",
      "|   |   |--- class: 1\n",
      "|--- feature_1 > -0.037112255696725716\n",
      "|   |--- feature_3 <= -0.07696973751446881\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_3 > -0.07696973751446881\n",
      "|   |   |--- class: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We should implement vanilla TreeClassifier --> which uses identity bins\n",
    "\n",
    "tc = TreeClassifier(data=pca_train_vecs_huge, labels=pca_train_labels_huge, max_depth=2, classes=classes, solver=\"EXACT\", verbose=True, random_state=0)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)\n",
    "tc.tree_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec262c",
   "metadata": {},
   "source": [
    "# Verify our implementation of baseline models agrees with sklearn's in terms of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264ead3d",
   "metadata": {},
   "source": [
    "# Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1d76ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_structures.wrappers.random_forest_classifier import RandomForestClassifier as RFC_ours\n",
    "from data_structures.wrappers.extremely_random_forest_classifier import ExtremelyRandomForestClassifier as ERFC_ours\n",
    "\n",
    "from data_structures.wrappers.random_forest_regressor import RandomForestRegressor as RFR_ours\n",
    "from data_structures.wrappers.extremely_random_forest_regressor import ExtremelyRandomForestRegressor as ERFR_ours\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC_sklearn\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ERFC_sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR_sklearn\n",
    "from sklearn.ensemble import ExtraTreesRegressor as ERFR_sklearn\n",
    "\n",
    "from utils.constants import GINI, BEST, EXACT, MSE\n",
    "\n",
    "# TODO(@motiwari): Allow for gradient boosted comparisons as well\n",
    "def compare_accuracies(\n",
    "    compare: str = \"RFC\",\n",
    "    train_data: np.ndarray = None,\n",
    "    train_targets: np.ndarray = None,\n",
    "    test_data: np.ndarray = None,\n",
    "    test_targets: np.ndarray = None,\n",
    "    num_seeds: int = 10,\n",
    ") -> bool:\n",
    "    our_train_accs = []\n",
    "    our_test_accs = []\n",
    "    their_train_accs = []\n",
    "    their_test_accs = []\n",
    "    for seed in range(num_seeds):\n",
    "        # Ok to have n_jobs = -1 throughout?\n",
    "        if compare == \"RFC\":\n",
    "            our_model = RFC_ours(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = RFC_sklearn(n_estimators=5, criterion='gini', max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        elif compare == \"ERFC\":\n",
    "            our_model = ERFC_ours(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, num_bins=None, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = ERFC_sklearn(n_estimators=5, criterion='gini', max_depth=5, min_samples_split=2, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=False, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        elif compare == \"RFR\":\n",
    "            our_model = RFR_ours(data=train_data, labels=train_targets, n_estimators=1, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=MSE, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = RFR_sklearn(n_estimators=1, criterion='squared_error', max_depth=5, min_samples_split=2, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, n_jobs=-1, random_state=seed, verbose=0)    \n",
    "        elif compare == \"ERFR\":\n",
    "            our_model = ERFR_ours(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, num_bins=None, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=MSE, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = ERFR_sklearn(n_estimators=5, criterion='squared_error', max_depth=5, min_samples_split=2, max_features='auto', min_impurity_decrease=0.0, bootstrap=False, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Need to decide what models to compare\")\n",
    "        \n",
    "        our_model.fit()\n",
    "        their_model.fit(train_data, train_targets)\n",
    "\n",
    "        if compare == \"RFC\" or compare == \"ERFC\" or compare == \"HRFC\":\n",
    "            our_train_acc = np.mean(our_model.predict_batch(train_data)[0] == train_targets)\n",
    "            our_test_acc = np.mean(our_model.predict_batch(test_data)[0] == test_targets)\n",
    "            their_train_acc = np.mean(their_model.predict(train_data) == train_targets)\n",
    "            their_test_acc = np.mean(their_model.predict(test_data) == test_targets)\n",
    "        elif compare == \"RFR\" or compare == \"ERFR\" or compare == \"HRFR\":\n",
    "            our_train_acc = np.mean((our_model.predict_batch(train_data) - train_targets)**2)\n",
    "            our_test_acc = np.mean((our_model.predict_batch(test_data) - test_targets)**2)\n",
    "            their_train_acc = np.mean((our_model.predict_batch(train_data) - train_targets)**2)\n",
    "            their_test_acc = np.mean((our_model.predict_batch(test_data) - test_targets)**2)\n",
    "\n",
    "        print(\"(Ours) Train accuracy:\", our_train_acc)\n",
    "        print(\"(Ours) Test accuracy:\", our_test_acc)\n",
    "        print(\"(Theirs) Train accuracy:\", their_train_acc)\n",
    "        print(\"(Theirs) Test accuracy:\", their_test_acc)\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        our_train_accs.append(our_train_acc)\n",
    "        our_test_accs.append(our_test_acc)\n",
    "        their_train_accs.append(their_train_acc)\n",
    "        their_test_accs.append(their_test_acc)\n",
    "    \n",
    "    our_avg_train = np.mean(our_train_accs)\n",
    "    our_std_train = np.std(our_train_accs)\n",
    "\n",
    "    our_avg_test = np.mean(our_test_accs)\n",
    "    our_std_test = np.std(our_test_accs)\n",
    "    \n",
    "    their_avg_train = np.mean(their_train_accs)\n",
    "    their_std_train = np.std(their_train_accs)\n",
    "    \n",
    "    their_avg_test = np.mean(their_test_accs)\n",
    "    their_std_test = np.std(their_test_accs)\n",
    "    \n",
    "    # See if confidence intervals overlap\n",
    "    overlap = np.abs(their_avg_test - our_avg_test) < their_std_test + our_std_test\n",
    "    return overlap, our_avg_train, our_std_train, our_avg_test, our_std_test, their_avg_train, their_std_train, their_avg_test, their_std_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f79d3ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 0.869524697110904\n",
      "(Ours) Test accuracy: 0.7812061711079944\n",
      "(Theirs) Train accuracy: 0.8741845293569431\n",
      "(Theirs) Test accuracy: 0.7643758765778401\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8574091332712023\n",
      "(Ours) Test accuracy: 0.7601683029453016\n",
      "(Theirs) Train accuracy: 0.8779123951537745\n",
      "(Theirs) Test accuracy: 0.7713884992987378\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8797763280521901\n",
      "(Ours) Test accuracy: 0.7784011220196353\n",
      "(Theirs) Train accuracy: 0.8872320596458527\n",
      "(Theirs) Test accuracy: 0.7601683029453016\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8797763280521901\n",
      "(Ours) Test accuracy: 0.7643758765778401\n",
      "(Theirs) Train accuracy: 0.8704566635601119\n",
      "(Theirs) Test accuracy: 0.7812061711079944\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8527493010251631\n",
      "(Ours) Test accuracy: 0.7657784011220197\n",
      "(Theirs) Train accuracy: 0.8583410997204101\n",
      "(Theirs) Test accuracy: 0.7727910238429172\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8359739049394221\n",
      "(Ours) Test accuracy: 0.6661991584852734\n",
      "(Theirs) Train accuracy: 0.8238583410997204\n",
      "(Theirs) Test accuracy: 0.7054698457223001\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8993476234855545\n",
      "(Ours) Test accuracy: 0.7812061711079944\n",
      "(Theirs) Train accuracy: 0.8490214352283317\n",
      "(Theirs) Test accuracy: 0.7166900420757363\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8546132339235788\n",
      "(Ours) Test accuracy: 0.6886395511921458\n",
      "(Theirs) Train accuracy: 0.8835041938490215\n",
      "(Theirs) Test accuracy: 0.7980364656381487\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8890959925442684\n",
      "(Ours) Test accuracy: 0.7727910238429172\n",
      "(Theirs) Train accuracy: 0.875116495806151\n",
      "(Theirs) Test accuracy: 0.7489481065918654\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8527493010251631\n",
      "(Ours) Test accuracy: 0.7208976157082749\n",
      "(Theirs) Train accuracy: 0.8816402609506058\n",
      "(Theirs) Test accuracy: 0.7741935483870968\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 0.8671015843429636,\n",
       " 0.018658890015434363,\n",
       " 0.7479663394109396,\n",
       " 0.03927594635191804,\n",
       " 0.8681267474370922,\n",
       " 0.018415477811157405,\n",
       " 0.7593267882187938,\n",
       " 0.027161219493767656)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pca_train_vecs\n",
    "train_labels = ng_train.target\n",
    "test_data = pca_test_vecs\n",
    "test_labels = ng_test.target\n",
    "\n",
    "compare_accuracies(\"RFC\", train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccd52dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 0.7297297297297297\n",
      "(Ours) Test accuracy: 0.6479663394109397\n",
      "(Theirs) Train accuracy: 0.8136067101584343\n",
      "(Theirs) Test accuracy: 0.7475455820476858\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7427772600186393\n",
      "(Ours) Test accuracy: 0.6339410939691444\n",
      "(Theirs) Train accuracy: 0.7176141658900279\n",
      "(Theirs) Test accuracy: 0.6283309957924264\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6877912395153775\n",
      "(Ours) Test accuracy: 0.5960729312762973\n",
      "(Theirs) Train accuracy: 0.7269338303821062\n",
      "(Theirs) Test accuracy: 0.6100981767180925\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7110904007455732\n",
      "(Ours) Test accuracy: 0.6577840112201964\n",
      "(Theirs) Train accuracy: 0.7399813606710158\n",
      "(Theirs) Test accuracy: 0.6311360448807855\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.782851817334576\n",
      "(Ours) Test accuracy: 0.7138849929873773\n",
      "(Theirs) Train accuracy: 0.7260018639328985\n",
      "(Theirs) Test accuracy: 0.6283309957924264\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6905871388630009\n",
      "(Ours) Test accuracy: 0.6044880785413744\n",
      "(Theirs) Train accuracy: 0.7688723205964585\n",
      "(Theirs) Test accuracy: 0.6479663394109397\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6840633737185461\n",
      "(Ours) Test accuracy: 0.5946704067321178\n",
      "(Theirs) Train accuracy: 0.7409133271202236\n",
      "(Theirs) Test accuracy: 0.664796633941094\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7036346691519105\n",
      "(Ours) Test accuracy: 0.6115007012622721\n",
      "(Theirs) Train accuracy: 0.6999068033550793\n",
      "(Theirs) Test accuracy: 0.6325385694249649\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7260018639328985\n",
      "(Ours) Test accuracy: 0.6072931276297335\n",
      "(Theirs) Train accuracy: 0.750232991612302\n",
      "(Theirs) Test accuracy: 0.6886395511921458\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7893755824790307\n",
      "(Ours) Test accuracy: 0.7223001402524544\n",
      "(Theirs) Train accuracy: 0.7036346691519105\n",
      "(Theirs) Test accuracy: 0.6002805049088359\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 0.7247903075489284,\n",
       " 0.035671434343217547,\n",
       " 0.6389901823281907,\n",
       " 0.04445892194481986,\n",
       " 0.7387698042870456,\n",
       " 0.03184285378036402,\n",
       " 0.6479663394109397,\n",
       " 0.04105350098507873)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_accuracies(\"ERFC\", train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a81cc33",
   "metadata": {},
   "source": [
    "# Regression: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2065315",
   "metadata": {},
   "source": [
    "### Weirdly, we get exactly the same results as sklearn for all seeds. We should investigate whether this is a bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96c4cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "data, targets = fetch_california_housing(return_X_y=True)\n",
    "random_idcs = np.random.choice(len(data), size=len(data),replace=False)\n",
    "data = data[random_idcs]\n",
    "targets = targets[random_idcs]\n",
    "\n",
    "TRAIN_TEST_SPLIT = 16000\n",
    "train_data = data[:TRAIN_TEST_SPLIT]\n",
    "train_targets = targets[:TRAIN_TEST_SPLIT]\n",
    "\n",
    "test_data = data[TRAIN_TEST_SPLIT:]\n",
    "test_targets = targets[TRAIN_TEST_SPLIT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edf5a291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 0.6434856262945001\n",
      "(Ours) Test accuracy: 0.6404177456199935\n",
      "(Theirs) Train accuracy: 0.6434856262945001\n",
      "(Theirs) Test accuracy: 0.6404177456199935\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.5434331358870558\n",
      "(Ours) Test accuracy: 0.5382767683216493\n",
      "(Theirs) Train accuracy: 0.5434331358870558\n",
      "(Theirs) Test accuracy: 0.5382767683216493\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.5923178293494454\n",
      "(Ours) Test accuracy: 0.590479631138747\n",
      "(Theirs) Train accuracy: 0.5923178293494454\n",
      "(Theirs) Test accuracy: 0.590479631138747\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.5345675261236849\n",
      "(Ours) Test accuracy: 0.5391597289478919\n",
      "(Theirs) Train accuracy: 0.5345675261236849\n",
      "(Theirs) Test accuracy: 0.5391597289478919\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6415624657014056\n",
      "(Ours) Test accuracy: 0.6541603944410617\n",
      "(Theirs) Train accuracy: 0.6415624657014056\n",
      "(Theirs) Test accuracy: 0.6541603944410617\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.5851923679614034\n",
      "(Ours) Test accuracy: 0.5822401526694374\n",
      "(Theirs) Train accuracy: 0.5851923679614034\n",
      "(Theirs) Test accuracy: 0.5822401526694374\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.550079390427507\n",
      "(Ours) Test accuracy: 0.5411039904025903\n",
      "(Theirs) Train accuracy: 0.550079390427507\n",
      "(Theirs) Test accuracy: 0.5411039904025903\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6086532091271617\n",
      "(Ours) Test accuracy: 0.6137355271466728\n",
      "(Theirs) Train accuracy: 0.6086532091271617\n",
      "(Theirs) Test accuracy: 0.6137355271466728\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.5735563083437678\n",
      "(Ours) Test accuracy: 0.5601252082064871\n",
      "(Theirs) Train accuracy: 0.5735563083437678\n",
      "(Theirs) Test accuracy: 0.5601252082064871\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.64444858112831\n",
      "(Ours) Test accuracy: 0.6408042715664896\n",
      "(Theirs) Train accuracy: 0.64444858112831\n",
      "(Theirs) Test accuracy: 0.6408042715664896\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 0.5917296440344243,\n",
       " 0.039919721088819346,\n",
       " 0.590050341846102,\n",
       " 0.04290305732151865,\n",
       " 0.5917296440344243,\n",
       " 0.039919721088819346,\n",
       " 0.590050341846102,\n",
       " 0.04290305732151865)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_accuracies(\"RFR\", train_data, train_targets, test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "159edac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 1.211010772558373\n",
      "(Ours) Test accuracy: 1.1804533771031367\n",
      "(Theirs) Train accuracy: 1.211010772558373\n",
      "(Theirs) Test accuracy: 1.1804533771031367\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 1.2070874225010775\n",
      "(Ours) Test accuracy: 1.1800898186449236\n",
      "(Theirs) Train accuracy: 1.2070874225010775\n",
      "(Theirs) Test accuracy: 1.1800898186449236\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2z/dxb5rnhd7wx6yg77m3z4c1n40000gn/T/ipykernel_67293/3597989300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompare_accuracies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ERFR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/2z/dxb5rnhd7wx6yg77m3z4c1n40000gn/T/ipykernel_67293/207569110.py\u001b[0m in \u001b[0;36mcompare_accuracies\u001b[0;34m(compare, train_data, train_targets, test_data, test_targets, num_seeds)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Need to decide what models to compare\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mour_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mtheir_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_targets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/RandomForest/data_structures/forest_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, labels)\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 )\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/RandomForest/data_structures/tree_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_budget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_budget\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                         \u001b[0;31m# Runs solve_mab if not previously computed, which incurs cost!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_best_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/RandomForest/data_structures/node.py\u001b[0m in \u001b[0;36mcalculate_best_split\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m             )\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEXACT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             results = solve_exactly(\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_idcs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/RandomForest/utils/solvers.py\u001b[0m in \u001b[0;36msolve_exactly\u001b[0;34m(data, labels, discrete_bins_dict, binning_type, num_bins, is_classification, impurity_measure, min_impurity_reduction)\u001b[0m\n\u001b[1;32m    129\u001b[0m     )\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     estimates[accesses], _cb_delta, num_queries, _ = sample_targets(\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mis_classification\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_classification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/RandomForest/utils/solvers.py\u001b[0m in \u001b[0;36msample_targets\u001b[0;34m(is_classification, data, labels, arms, histograms, batch_size, impurity_measure, population_idcs)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf2bin_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mHistogram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistograms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_labels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This is where the labels are used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;31m# TODO(@motiwari): Can make this more efficient because a lot of histogram computation is reused across steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         i_r, cb_d = get_impurity_reductions(\n",
      "\u001b[0;32m~/Desktop/RandomForest/data_structures/histogram.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    134\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_pile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mleft_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_bins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_pile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mleft_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlinear_bin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "compare_accuracies(\"ERFR\", train_data, train_targets, test_data, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984f71d",
   "metadata": {},
   "source": [
    "# Verify MAB solvers are faster in speed but have no change in accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a6aace",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3976aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Any, Tuple\n",
    "\n",
    "# Classification #\n",
    "# Vanilla random forest + H + GB + GBH\n",
    "from data_structures.wrappers.random_forest_classifier import RandomForestClassifier as RFC\n",
    "from data_structures.wrappers.histogram_random_forest_classifier import HistogramRandomForestClassifier as HRFC\n",
    "from data_structures.wrappers.gradient_boosted_random_forest_classifier import GradientBoostedRandomForestClassifier as GBRFC\n",
    "from data_structures.wrappers.gradient_boosted_histogram_random_forest_classifier import GradientBoostedHistogramRandomForestClassifier as GBHRFC\n",
    "\n",
    "# Extremely random forest + GB (already histogrammed)\n",
    "from data_structures.wrappers.extremely_random_forest_classifier import ExtremelyRandomForestClassifier as ERFC\n",
    "from data_structures.wrappers.gradient_boosted_extremely_random_forest_classifier import GradientBoostedExtremelyRandomForestClassifier as GBERFC\n",
    "\n",
    "# Random patches + H + GB + GBH\n",
    "from data_structures.wrappers.random_patches_classifier import RandomPatchesClassifier as RPC\n",
    "from data_structures.wrappers.histogram_random_patches_classifier import HistogramRandomPatchesClassifier as HRPC\n",
    "from data_structures.wrappers.gradient_boosted_random_patches_classifier import GradientBoostedRandomPatchesClassifier as GBRPC\n",
    "from data_structures.wrappers.histogram_random_patches_classifier import HistogramRandomPatchesClassifier as HBRPC\n",
    "\n",
    "\n",
    "# Regression #\n",
    "# Vanilla random forest + H + GB + GBH\n",
    "from data_structures.wrappers.random_forest_regressor import RandomForestRegressor as RFR\n",
    "from data_structures.wrappers.histogram_random_forest_regressor import HistogramRandomForestRegressor as HRFR\n",
    "from data_structures.wrappers.gradient_boosted_random_forest_regressor import GradientBoostedRandomForestRegressor as GBRFR\n",
    "from data_structures.wrappers.gradient_boosted_histogram_random_forest_regressor import GradientBoostedHistogramRandomForestRegressor as GBHRFR\n",
    "\n",
    "# Extremely random forest + GB (already histogrammed)\n",
    "from data_structures.wrappers.extremely_random_forest_regressor import ExtremelyRandomForestRegressor as ERFR\n",
    "from data_structures.wrappers.gradient_boosted_extremely_random_forest_regressor import GradientBoostedExtremelyRandomForestRegressor as GBERFR\n",
    "\n",
    "# Random patches + H + GB + GBH\n",
    "from data_structures.wrappers.random_patches_regressor import RandomPatchesRegressor as RPR\n",
    "from data_structures.wrappers.histogram_random_patches_regressor import HistogramRandomPatchesRegressor as HRPR\n",
    "from data_structures.wrappers.gradient_boosted_random_patches_regressor import GradientBoostedRandomPatchesRegressor as GBRPR\n",
    "from data_structures.wrappers.histogram_random_patches_regressor import HistogramRandomPatchesRegressor as HBRPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4badcd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_measured_fit(\n",
    "    model: Any,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Returns wall clock time of training the model, in seconds.\n",
    "    \n",
    "    Has a side effect: trains the model.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    model.fit()\n",
    "    end = time.time()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73bba5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.constants import GINI, BEST, EXACT, MAB, MSE\n",
    "\n",
    "\n",
    "def compare_runtimes(\n",
    "    compare: str = \"HRFC\",\n",
    "    train_data: np.ndarray = None,\n",
    "    train_targets: np.ndarray = None,\n",
    "    test_data: np.ndarray = None,\n",
    "    test_targets: np.ndarray = None,\n",
    "    num_seeds: int = 10,\n",
    ") -> bool:\n",
    "    # Runtimes\n",
    "    our_train_times = []\n",
    "    their_train_times = []\n",
    "    \n",
    "    # For accuracies\n",
    "    our_train_accs = []\n",
    "    our_test_accs = []\n",
    "    their_train_accs = []\n",
    "    their_test_accs = []\n",
    "    for seed in range(num_seeds):\n",
    "        # Ok to have n_jobs = -1 throughout?\n",
    "        if compare == \"HRFC\":\n",
    "            our_model = HRFC(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=MAB, random_state=seed, verbose=False)\n",
    "            their_model = HRFC(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Need to decide what models to compare\")\n",
    "        \n",
    "        assert 'sklearn' not in their_model.__module__, \"Cannot use sklearn models for runtime comparisons\"\n",
    "        \n",
    "        our_runtime = time_measured_fit(our_model)\n",
    "        our_train_times.append(our_runtime)\n",
    "\n",
    "        their_runtime = time_measured_fit(their_model)\n",
    "        their_train_times.append(their_runtime)\n",
    "\n",
    "        if compare == \"RFC\" or compare == \"ERFC\" or compare == \"HRFC\":\n",
    "            our_train_acc = np.mean(our_model.predict_batch(train_data)[0] == train_targets)\n",
    "            our_test_acc = np.mean(our_model.predict_batch(test_data)[0] == test_targets)\n",
    "            their_train_acc = np.mean(their_model.predict_batch(train_data)[0] == train_targets)\n",
    "            their_test_acc = np.mean(their_model.predict_batch(test_data)[0] == test_targets)\n",
    "\n",
    "        print(\"(Ours) Train accuracy:\", our_train_acc)\n",
    "        print(\"(Ours) Test accuracy:\", our_test_acc)\n",
    "        print(\"(Theirs) Train accuracy:\", their_train_acc)\n",
    "        print(\"(Theirs) Test accuracy:\", their_test_acc)\n",
    "        print(\"*\" * 30)\n",
    "        print(\"(Ours) Runtime:\", our_runtime)\n",
    "        print(\"(Theirs) Runtime:\", their_runtime)\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        our_train_accs.append(our_train_acc)\n",
    "        our_test_accs.append(our_test_acc)\n",
    "        their_train_accs.append(their_train_acc)\n",
    "        their_test_accs.append(their_test_acc)\n",
    "    \n",
    "    # For accuracies\n",
    "    our_avg_train = np.mean(our_train_accs)\n",
    "    our_std_train = np.std(our_train_accs)\n",
    "\n",
    "    our_avg_test = np.mean(our_test_accs)\n",
    "    our_std_test = np.std(our_test_accs)\n",
    "    \n",
    "    their_avg_train = np.mean(their_train_accs)\n",
    "    their_std_train = np.std(their_train_accs)\n",
    "    \n",
    "    their_avg_test = np.mean(their_test_accs)\n",
    "    their_std_test = np.std(their_test_accs)\n",
    "    \n",
    "    # For runtimes\n",
    "    our_avg_train_time = np.mean(our_train_times)\n",
    "    our_std_train_time = np.std(our_train_times)\n",
    "    \n",
    "    their_avg_train_time = np.mean(their_train_times)\n",
    "    their_std_train_time = np.std(their_train_times)\n",
    "    \n",
    "    \n",
    "    # See if confidence intervals overlap\n",
    "    overlap = np.abs(their_avg_test - our_avg_test) < their_std_test + our_std_test\n",
    "    return overlap, our_avg_train, our_std_train, our_avg_test, our_std_test, their_avg_train, their_std_train, their_avg_test, their_std_test, our_avg_train_time, our_std_train_time, their_avg_train_time, their_std_train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e280093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 0.8713886300093197\n",
      "(Ours) Test accuracy: 0.7755960729312763\n",
      "(Theirs) Train accuracy: 0.8872320596458527\n",
      "(Theirs) Test accuracy: 0.7840112201963534\n",
      "******************************\n",
      "(Ours) Runtime: 19.933643102645874\n",
      "(Theirs) Runtime: 25.426739931106567\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8732525629077353\n",
      "(Ours) Test accuracy: 0.761570827489481\n",
      "(Theirs) Train accuracy: 0.8536812674743709\n",
      "(Theirs) Test accuracy: 0.7741935483870968\n",
      "******************************\n",
      "(Ours) Runtime: 23.75546097755432\n",
      "(Theirs) Runtime: 25.384379148483276\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8657968313140727\n",
      "(Ours) Test accuracy: 0.788218793828892\n",
      "(Theirs) Train accuracy: 0.848089468779124\n",
      "(Theirs) Test accuracy: 0.758765778401122\n",
      "******************************\n",
      "(Ours) Runtime: 23.601354837417603\n",
      "(Theirs) Runtime: 24.36001205444336\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8630009319664492\n",
      "(Ours) Test accuracy: 0.7489481065918654\n",
      "(Theirs) Train accuracy: 0.8611369990680335\n",
      "(Theirs) Test accuracy: 0.7433380084151473\n",
      "******************************\n",
      "(Ours) Runtime: 18.911430835723877\n",
      "(Theirs) Runtime: 25.868072748184204\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8341099720410066\n",
      "(Ours) Test accuracy: 0.758765778401122\n",
      "(Theirs) Train accuracy: 0.8835041938490215\n",
      "(Theirs) Test accuracy: 0.791023842917251\n",
      "******************************\n",
      "(Ours) Runtime: 23.08477210998535\n",
      "(Theirs) Runtime: 25.917784690856934\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8499534016775396\n",
      "(Ours) Test accuracy: 0.7405329593267882\n",
      "(Theirs) Train accuracy: 0.875116495806151\n",
      "(Theirs) Test accuracy: 0.791023842917251\n",
      "******************************\n",
      "(Ours) Runtime: 19.895964860916138\n",
      "(Theirs) Runtime: 23.8307888507843\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8564771668219944\n",
      "(Ours) Test accuracy: 0.7391304347826086\n",
      "(Theirs) Train accuracy: 0.8760484622553588\n",
      "(Theirs) Test accuracy: 0.7966339410939691\n",
      "******************************\n",
      "(Ours) Runtime: 20.44783306121826\n",
      "(Theirs) Runtime: 22.53705072402954\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8676607642124884\n",
      "(Ours) Test accuracy: 0.7840112201963534\n",
      "(Theirs) Train accuracy: 0.8602050326188257\n",
      "(Theirs) Test accuracy: 0.7685834502103787\n",
      "******************************\n",
      "(Ours) Runtime: 22.087934017181396\n",
      "(Theirs) Runtime: 21.949432134628296\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8322460391425909\n",
      "(Ours) Test accuracy: 0.7573632538569425\n",
      "(Theirs) Train accuracy: 0.8760484622553588\n",
      "(Theirs) Test accuracy: 0.7363253856942497\n",
      "******************************\n",
      "(Ours) Runtime: 19.555191040039062\n",
      "(Theirs) Runtime: 21.739092111587524\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8620689655172413\n",
      "(Ours) Test accuracy: 0.7685834502103787\n",
      "(Theirs) Train accuracy: 0.8685927306616962\n",
      "(Theirs) Test accuracy: 0.7755960729312763\n",
      "******************************\n",
      "(Ours) Runtime: 17.11106514930725\n",
      "(Theirs) Runtime: 21.845423936843872\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 0.8575955265610439,\n",
       " 0.013809466126368275,\n",
       " 0.7622720897615709,\n",
       " 0.016080174797061916,\n",
       " 0.8689655172413794,\n",
       " 0.012209827575144324,\n",
       " 0.7719495091164095,\n",
       " 0.019425850988141116,\n",
       " 20.838464999198912,\n",
       " 2.094346177385369,\n",
       " 23.885877633094786,\n",
       " 1.6506556262047691)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = ng_test.target\n",
    "compare_runtimes(\"HRFC\", pca_train_vecs_huge, pca_train_labels_huge, pca_test_vecs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f84f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "\n",
    "mndata = MNIST('mnist/')\n",
    "\n",
    "train_images, train_labels = mndata.load_training()\n",
    "test_images, test_labels = mndata.load_testing()\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b6fdd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ec27e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2z/dxb5rnhd7wx6yg77m3z4c1n40000gn/T/ipykernel_44267/2479672015.py:39: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  our_test_acc = np.mean(our_model.predict_batch(test_data)[0] == test_targets)\n",
      "/var/folders/2z/dxb5rnhd7wx6yg77m3z4c1n40000gn/T/ipykernel_44267/2479672015.py:41: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  their_test_acc = np.mean(their_model.predict_batch(test_data)[0] == test_targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 0.7571\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7843333333333333\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 63.211597204208374\n",
      "(Theirs) Runtime: 277.41305923461914\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.75775\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7789833333333334\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 64.38117504119873\n",
      "(Theirs) Runtime: 257.7257170677185\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7639\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.75385\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 61.45366072654724\n",
      "(Theirs) Runtime: 222.81906414031982\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7476666666666667\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7629666666666667\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 57.80263113975525\n",
      "(Theirs) Runtime: 220.82625699043274\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7718666666666667\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7719833333333334\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 54.77347683906555\n",
      "(Theirs) Runtime: 227.3582911491394\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7646666666666667\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7576333333333334\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 51.59064817428589\n",
      "(Theirs) Runtime: 217.1352949142456\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7571\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7656\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 51.49304819107056\n",
      "(Theirs) Runtime: 216.4136199951172\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7624666666666666\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.74835\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 53.94985604286194\n",
      "(Theirs) Runtime: 216.2584729194641\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7652666666666667\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7613666666666666\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 50.04034900665283\n",
      "(Theirs) Runtime: 210.312518119812\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.76185\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7633\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 51.11007809638977\n",
      "(Theirs) Runtime: 213.75734615325928\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 0.7609633333333333,\n",
       " 0.006162497689880117,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7648366666666666,\n",
       " 0.010460448790032337,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 55.980652046203616,\n",
       " 5.100300028883073,\n",
       " 228.00196406841278,\n",
       " 20.760141606448816)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_runtimes(\"HRFC\", train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "796002f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC_sklearn\n",
    "rfc = RFC_sklearn()\n",
    "rfc.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca7a08cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rfc.predict(test_images) == test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbdced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
