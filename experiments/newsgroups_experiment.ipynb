{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592af781",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5de16cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.datasets import *\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import copy\n",
    "\n",
    "from data_structures.tree_classifier import TreeClassifier\n",
    "import utils.utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a183e",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all datasets from sklearn\n",
    "for m in [fetch_olivetti_faces, fetch_20newsgroups_vectorized, fetch_lfw_people, fetch_lfw_pairs, fetch_covtype, fetch_rcv1, fetch_kddcup99, fetch_california_housing]:\n",
    "    print(m)\n",
    "    try:\n",
    "        all_ = m()\n",
    "        train = m(subset='train')\n",
    "        test = m(subset='test')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dea93964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints:  1073\n",
      "Number of features:  18217\n",
      "Balance:  0.5526561043802423\n"
     ]
    }
   ],
   "source": [
    "# Download the data from two categories\n",
    "cats = ['alt.atheism', 'sci.space']\n",
    "ng_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "ng_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "trans = vectorizer.fit(ng_train.data)\n",
    "train_vectors = vectorizer.transform(ng_train.data)\n",
    "test_vectors = vectorizer.transform(ng_test.data)\n",
    "print(\"Number of datapoints: \", len(ng_train.data))\n",
    "print(\"Number of features: \", train_vectors.shape[1])\n",
    "print(\"Balance: \", np.sum(ng_train.target) / len(ng_train.target)) # 55-45, roughly balanced\n",
    "\n",
    "N_COMPONENTS=100\n",
    "pca = PCA(n_components=N_COMPONENTS)\n",
    "pca.fit(train_vectors.toarray())\n",
    "pca_train_vecs = pca.transform(train_vectors.toarray())\n",
    "pca_test_vecs = pca.transform(test_vectors.toarray())\n",
    "\n",
    "classes_arr = np.unique(ng_train.target)\n",
    "classes = utils.utils.class_to_idx(classes_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da9b97",
   "metadata": {},
   "source": [
    "# Compare our implementation's accuracy to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "983ecf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Decision Tree Accuracy: 0.7812061711079944\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(pca_train_vecs,ng_train.target)\n",
    "print(\"sklearn Decision Tree Accuracy:\", np.mean(dt.predict(pca_test_vecs) == ng_test.target))\n",
    "\n",
    "#cross_val_score(dt, pca_train_vecs, ng_train.target, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2554a668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Random Forest Accuracy: 0.8022440392706872\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(pca_train_vecs,ng_train.target)\n",
    "print(\"sklearn Random Forest Accuracy:\", np.mean(rf.predict(pca_test_vecs) == ng_test.target))\n",
    "\n",
    "#cross_val_score(rf, pca_train_vecs, ng_train.target, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a84470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9086672879776329\n",
      "Test accuracy: 0.7812061711079944\n",
      "Num queries: 5271\n",
      "Runtime: 21.913602113723755\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs, labels=ng_train.target, max_depth=5, classes=classes, verbose=False)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee840a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9086672879776329\n",
      "Test accuracy: 0.7812061711079944\n",
      "Num queries: 5344\n",
      "Runtime: 12.790964126586914\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs, labels=ng_train.target, max_depth=5, classes=classes, solver=\"EXACT\", verbose=False)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ffd149",
   "metadata": {},
   "source": [
    "# Make the dataset huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "877237a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1073, 100)\n",
      "(17168, 100)\n"
     ]
    }
   ],
   "source": [
    "doublings = 4\n",
    "pca_train_vecs_huge = copy.deepcopy(pca_train_vecs)\n",
    "pca_train_labels_huge = copy.deepcopy(ng_train.target)\n",
    "print(pca_train_vecs_huge.shape)\n",
    "for i in range(doublings):\n",
    "    pca_train_vecs_huge = np.concatenate((pca_train_vecs_huge, pca_train_vecs_huge))\n",
    "    pca_train_labels_huge = np.concatenate((pca_train_labels_huge, pca_train_labels_huge))\n",
    "print(pca_train_vecs_huge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8eca539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated split with 6600 queries\n",
      "Calculated split with 6576 queries\n",
      "Calculated split with 8500 queries\n",
      "Fitting finished\n",
      "Train accuracy: 0.7996272134203168\n",
      "Test accuracy: 0.7531556802244039\n",
      "Num queries: 21676\n",
      "Runtime: 12.382985830307007\n",
      "|--- feature_1 <= -0.02424286634709316\n",
      "|   |--- feature_18 <= 0.028246263503167335\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_18 > 0.028246263503167335\n",
      "|   |   |--- class: 0\n",
      "|--- feature_1 > -0.02424286634709316\n",
      "|   |--- feature_3 <= -0.016323886201712157\n",
      "|   |   |--- class: 1\n",
      "|   |--- feature_3 > -0.016323886201712157\n",
      "|   |   |--- class: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs_huge, labels=pca_train_labels_huge, max_depth=2, classes=classes, verbose=True, random_state=0)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)\n",
    "tc.tree_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58f5a946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated split with 17168 queries\n",
      "Calculated split with 6576 queries\n",
      "Calculated split with 10592 queries\n",
      "Fitting finished\n",
      "Train accuracy: 0.7996272134203168\n",
      "Test accuracy: 0.7531556802244039\n",
      "Num queries: 34336\n",
      "Runtime: 21.095016956329346\n",
      "|--- feature_1 <= -0.02424286634709316\n",
      "|   |--- feature_18 <= 0.028246263503167335\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_18 > 0.028246263503167335\n",
      "|   |   |--- class: 0\n",
      "|--- feature_1 > -0.02424286634709316\n",
      "|   |--- feature_3 <= -0.016323886201712157\n",
      "|   |   |--- class: 1\n",
      "|   |--- feature_3 > -0.016323886201712157\n",
      "|   |   |--- class: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We should implement vanilla TreeClassifier --> which uses identity bins\n",
    "\n",
    "tc = TreeClassifier(data=pca_train_vecs_huge, labels=pca_train_labels_huge, max_depth=2, classes=classes, solver=\"EXACT\", verbose=True, random_state=0)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)\n",
    "tc.tree_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec262c",
   "metadata": {},
   "source": [
    "# Verify our implementation of baseline models agrees with sklearn's in terms of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264ead3d",
   "metadata": {},
   "source": [
    "# Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d76ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_structures.wrappers.random_forest_classifier import RandomForestClassifier as RFC_ours\n",
    "from data_structures.wrappers.extremely_random_forest_classifier import ExtremelyRandomForestClassifier as ERFC_ours\n",
    "\n",
    "from data_structures.wrappers.random_forest_regressor import RandomForestRegressor as RFR_ours\n",
    "from data_structures.wrappers.extremely_random_forest_regressor import ExtremelyRandomForestRegressor as ERFR_ours\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC_sklearn\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ERFC_sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR_sklearn\n",
    "from sklearn.ensemble import ExtraTreesRegressor as ERFR_sklearn\n",
    "\n",
    "from utils.constants import GINI, BEST, EXACT, MSE\n",
    "\n",
    "# TODO(@motiwari): Allow for gradient boosted comparisons as well\n",
    "def compare_accuracies(\n",
    "    compare: str = \"RFC\",\n",
    "    train_data: np.ndarray = None,\n",
    "    train_targets: np.ndarray = None,\n",
    "    test_data: np.ndarray = None,\n",
    "    test_targets: np.ndarray = None,\n",
    "    num_seeds: int = 10,\n",
    ") -> bool:\n",
    "    our_train_accs = []\n",
    "    our_test_accs = []\n",
    "    their_train_accs = []\n",
    "    their_test_accs = []\n",
    "    for seed in range(num_seeds):\n",
    "        # Ok to have n_jobs = -1 throughout?\n",
    "        if compare == \"RFC\":\n",
    "            our_model = RFC_ours(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = RFC_sklearn(n_estimators=5, criterion='gini', max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        elif compare == \"ERFC\":\n",
    "            our_model = ERFC_ours(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, num_bins=None, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = ERFC_sklearn(n_estimators=5, criterion='gini', max_depth=5, min_samples_split=2, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=False, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        elif compare == \"RFR\":\n",
    "            our_model = RFR_ours(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=MSE, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = RFR_sklearn(n_estimators=5, criterion='squared_error', max_depth=5, min_samples_split=2, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, n_jobs=-1, random_state=seed, verbose=0)    \n",
    "        elif compare == \"ERFR\":\n",
    "            our_model = ERFR_ours(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, num_bins=None, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=MSE, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = ERFR_sklearn(n_estimators=5, criterion='squared_error', max_depth=5, min_samples_split=2, max_features='auto', min_impurity_decrease=0.0, bootstrap=False, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Need to decide what models to compare\")\n",
    "        \n",
    "        our_model.fit()\n",
    "        their_model.fit(train_data, train_targets)\n",
    "\n",
    "        if compare == \"RFC\" or compare == \"ERFC\" or compare == \"HRFC\":\n",
    "            our_train_acc = np.mean(our_model.predict_batch(train_data)[0] == train_targets)\n",
    "            our_test_acc = np.mean(our_model.predict_batch(test_data)[0] == test_targets)\n",
    "            their_train_acc = np.mean(their_model.predict(train_data) == train_targets)\n",
    "            their_test_acc = np.mean(their_model.predict(test_data) == test_targets)\n",
    "        elif compare == \"RFR\" or compare == \"ERFR\" or compare == \"HRFR\":\n",
    "            our_train_acc = np.mean((our_model.predict_batch(train_data) - train_targets)**2)\n",
    "            our_test_acc = np.mean((our_model.predict_batch(test_data) - test_targets)**2)\n",
    "            their_train_acc = np.mean((our_model.predict_batch(train_data) - train_targets)**2)\n",
    "            their_test_acc = np.mean((our_model.predict_batch(test_data) - test_targets)**2)\n",
    "\n",
    "        print(\"(Ours) Train accuracy:\", our_train_acc)\n",
    "        print(\"(Ours) Test accuracy:\", our_test_acc)\n",
    "        print(\"(Theirs) Train accuracy:\", their_train_acc)\n",
    "        print(\"(Theirs) Test accuracy:\", their_test_acc)\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        our_train_accs.append(our_train_acc)\n",
    "        our_test_accs.append(our_test_acc)\n",
    "        their_train_accs.append(their_train_acc)\n",
    "        their_test_accs.append(their_test_acc)\n",
    "    \n",
    "    our_avg_train = np.mean(our_train_accs)\n",
    "    our_std_train = np.std(our_train_accs)\n",
    "\n",
    "    our_avg_test = np.mean(our_test_accs)\n",
    "    our_std_test = np.std(our_test_accs)\n",
    "    \n",
    "    their_avg_train = np.mean(their_train_accs)\n",
    "    their_std_train = np.std(their_train_accs)\n",
    "    \n",
    "    their_avg_test = np.mean(their_test_accs)\n",
    "    their_std_test = np.std(their_test_accs)\n",
    "    \n",
    "    # See if confidence intervals overlap\n",
    "    overlap = np.abs(their_avg_test - our_avg_test) < their_std_test + our_std_test\n",
    "    return overlap, our_avg_train, our_std_train, our_avg_test, our_std_test, their_avg_train, their_std_train, their_avg_test, their_std_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d3ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pca_train_vecs\n",
    "train_labels = ng_train.target\n",
    "test_data = pca_test_vecs\n",
    "test_labels = ng_test.target\n",
    "\n",
    "compare_accuracies(\"RFC\", train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd52dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_accuracies(\"ERFC\", train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a81cc33",
   "metadata": {},
   "source": [
    "# Regression: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2065315",
   "metadata": {},
   "source": [
    "### Weirdly, we get exactly the same results as sklearn for all seeds. We should investigate whether this is a bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c4cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "data, targets = fetch_california_housing(return_X_y=True)\n",
    "random_idcs = np.random.choice(len(data), size=len(data),replace=False)\n",
    "data = data[random_idcs]\n",
    "targets = targets[random_idcs]\n",
    "\n",
    "TRAIN_TEST_SPLIT = 16000\n",
    "train_data = data[:TRAIN_TEST_SPLIT]\n",
    "train_targets = targets[:TRAIN_TEST_SPLIT]\n",
    "\n",
    "test_data = data[TRAIN_TEST_SPLIT:]\n",
    "test_targets = targets[TRAIN_TEST_SPLIT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_accuracies(\"RFR\", train_data, train_targets, test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159edac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_accuracies(\"ERFR\", train_data, train_targets, test_data, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5984f71d",
   "metadata": {},
   "source": [
    "# Verify MAB solvers are faster in speed but have no change in accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a6aace",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3976aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Any, Tuple\n",
    "\n",
    "# Classification #\n",
    "# Vanilla random forest + H + GB + GBH\n",
    "from data_structures.wrappers.random_forest_classifier import RandomForestClassifier as RFC\n",
    "from data_structures.wrappers.histogram_random_forest_classifier import HistogramRandomForestClassifier as HRFC\n",
    "from data_structures.wrappers.gradient_boosted_random_forest_classifier import GradientBoostedRandomForestClassifier as GBRFC\n",
    "from data_structures.wrappers.gradient_boosted_histogram_random_forest_classifier import GradientBoostedHistogramRandomForestClassifier as GBHRFC\n",
    "\n",
    "# Extremely random forest + GB (already histogrammed)\n",
    "from data_structures.wrappers.extremely_random_forest_classifier import ExtremelyRandomForestClassifier as ERFC\n",
    "from data_structures.wrappers.gradient_boosted_extremely_random_forest_classifier import GradientBoostedExtremelyRandomForestClassifier as GBERFC\n",
    "\n",
    "# Random patches + H + GB + GBH\n",
    "from data_structures.wrappers.random_patches_classifier import RandomPatchesClassifier as RPC\n",
    "from data_structures.wrappers.histogram_random_patches_classifier import HistogramRandomPatchesClassifier as HRPC\n",
    "from data_structures.wrappers.gradient_boosted_random_patches_classifier import GradientBoostedRandomPatchesClassifier as GBRPC\n",
    "from data_structures.wrappers.histogram_random_patches_classifier import HistogramRandomPatchesClassifier as HBRPC\n",
    "\n",
    "\n",
    "# Regression #\n",
    "# Vanilla random forest + H + GB + GBH\n",
    "from data_structures.wrappers.random_forest_regressor import RandomForestRegressor as RFR\n",
    "from data_structures.wrappers.histogram_random_forest_regressor import HistogramRandomForestRegressor as HRFR\n",
    "from data_structures.wrappers.gradient_boosted_random_forest_regressor import GradientBoostedRandomForestRegressor as GBRFR\n",
    "from data_structures.wrappers.gradient_boosted_histogram_random_forest_regressor import GradientBoostedHistogramRandomForestRegressor as GBHRFR\n",
    "\n",
    "# Extremely random forest + GB (already histogrammed)\n",
    "from data_structures.wrappers.extremely_random_forest_regressor import ExtremelyRandomForestRegressor as ERFR\n",
    "from data_structures.wrappers.gradient_boosted_extremely_random_forest_regressor import GradientBoostedExtremelyRandomForestRegressor as GBERFR\n",
    "\n",
    "# Random patches + H + GB + GBH\n",
    "from data_structures.wrappers.random_patches_regressor import RandomPatchesRegressor as RPR\n",
    "from data_structures.wrappers.histogram_random_patches_regressor import HistogramRandomPatchesRegressor as HRPR\n",
    "from data_structures.wrappers.gradient_boosted_random_patches_regressor import GradientBoostedRandomPatchesRegressor as GBRPR\n",
    "from data_structures.wrappers.histogram_random_patches_regressor import HistogramRandomPatchesRegressor as HBRPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4badcd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_measured_fit(\n",
    "    model: Any,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Returns wall clock time of training the model, in seconds.\n",
    "    \n",
    "    Has a side effect: trains the model.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    model.fit()\n",
    "    end = time.time()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73bba5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.constants import GINI, BEST, EXACT, MAB, MSE\n",
    "\n",
    "\n",
    "def compare_runtimes(\n",
    "    compare: str = \"HRFC\",\n",
    "    train_data: np.ndarray = None,\n",
    "    train_targets: np.ndarray = None,\n",
    "    test_data: np.ndarray = None,\n",
    "    test_targets: np.ndarray = None,\n",
    "    num_seeds: int = 10,\n",
    ") -> bool:\n",
    "    # Runtimes\n",
    "    our_train_times = []\n",
    "    their_train_times = []\n",
    "    \n",
    "    # For accuracies\n",
    "    our_train_accs = []\n",
    "    our_test_accs = []\n",
    "    their_train_accs = []\n",
    "    their_test_accs = []\n",
    "    for seed in range(num_seeds):\n",
    "        # Ok to have n_jobs = -1 throughout?\n",
    "        if compare == \"HRFC\":\n",
    "            our_model = HRFC(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=MAB, random_state=seed, verbose=False)\n",
    "            their_model = HRFC(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Need to decide what models to compare\")\n",
    "        \n",
    "        assert 'sklearn' not in their_model.__module__, \"Cannot use sklearn models for runtime comparisons\"\n",
    "        \n",
    "        our_runtime = time_measured_fit(our_model)\n",
    "        our_train_times.append(our_runtime)\n",
    "\n",
    "        their_runtime = time_measured_fit(their_model)\n",
    "        their_train_times.append(their_runtime)\n",
    "\n",
    "        if compare == \"RFC\" or compare == \"ERFC\" or compare == \"HRFC\":\n",
    "            our_train_acc = np.mean(our_model.predict_batch(train_data)[0] == train_targets)\n",
    "            our_test_acc = np.mean(our_model.predict_batch(test_data)[0] == test_targets)\n",
    "            their_train_acc = np.mean(their_model.predict_batch(train_data)[0] == train_targets)\n",
    "            their_test_acc = np.mean(their_model.predict_batch(test_data)[0] == test_targets)\n",
    "\n",
    "        print(\"(Ours) Train accuracy:\", our_train_acc)\n",
    "        print(\"(Ours) Test accuracy:\", our_test_acc)\n",
    "        print(\"(Theirs) Train accuracy:\", their_train_acc)\n",
    "        print(\"(Theirs) Test accuracy:\", their_test_acc)\n",
    "        print(\"*\" * 30)\n",
    "        print(\"(Ours) Runtime:\", our_runtime)\n",
    "        print(\"(Theirs) Runtime:\", their_runtime)\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        our_train_accs.append(our_train_acc)\n",
    "        our_test_accs.append(our_test_acc)\n",
    "        their_train_accs.append(their_train_acc)\n",
    "        their_test_accs.append(their_test_acc)\n",
    "    \n",
    "    # For accuracies\n",
    "    our_avg_train = np.mean(our_train_accs)\n",
    "    our_std_train = np.std(our_train_accs)\n",
    "\n",
    "    our_avg_test = np.mean(our_test_accs)\n",
    "    our_std_test = np.std(our_test_accs)\n",
    "    \n",
    "    their_avg_train = np.mean(their_train_accs)\n",
    "    their_std_train = np.std(their_train_accs)\n",
    "    \n",
    "    their_avg_test = np.mean(their_test_accs)\n",
    "    their_std_test = np.std(their_test_accs)\n",
    "    \n",
    "    # For runtimes\n",
    "    our_avg_train_time = np.mean(our_train_times)\n",
    "    our_std_train_time = np.std(our_train_times)\n",
    "    \n",
    "    their_avg_train_time = np.mean(their_train_times)\n",
    "    their_std_train_time = np.std(their_train_times)\n",
    "    \n",
    "    \n",
    "    # See if confidence intervals overlap\n",
    "    overlap = np.abs(their_avg_test - our_avg_test) < their_std_test + our_std_test\n",
    "    return overlap, our_avg_train, our_std_train, our_avg_test, our_std_test, their_avg_train, their_std_train, their_avg_test, their_std_test, our_avg_train_time, our_std_train_time, their_avg_train_time, their_std_train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e280093d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 0.8713886300093197\n",
      "(Ours) Test accuracy: 0.7755960729312763\n",
      "(Theirs) Train accuracy: 0.8872320596458527\n",
      "(Theirs) Test accuracy: 0.7840112201963534\n",
      "******************************\n",
      "(Ours) Runtime: 19.933643102645874\n",
      "(Theirs) Runtime: 25.426739931106567\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8732525629077353\n",
      "(Ours) Test accuracy: 0.761570827489481\n",
      "(Theirs) Train accuracy: 0.8536812674743709\n",
      "(Theirs) Test accuracy: 0.7741935483870968\n",
      "******************************\n",
      "(Ours) Runtime: 23.75546097755432\n",
      "(Theirs) Runtime: 25.384379148483276\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8657968313140727\n",
      "(Ours) Test accuracy: 0.788218793828892\n",
      "(Theirs) Train accuracy: 0.848089468779124\n",
      "(Theirs) Test accuracy: 0.758765778401122\n",
      "******************************\n",
      "(Ours) Runtime: 23.601354837417603\n",
      "(Theirs) Runtime: 24.36001205444336\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8630009319664492\n",
      "(Ours) Test accuracy: 0.7489481065918654\n",
      "(Theirs) Train accuracy: 0.8611369990680335\n",
      "(Theirs) Test accuracy: 0.7433380084151473\n",
      "******************************\n",
      "(Ours) Runtime: 18.911430835723877\n",
      "(Theirs) Runtime: 25.868072748184204\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8341099720410066\n",
      "(Ours) Test accuracy: 0.758765778401122\n",
      "(Theirs) Train accuracy: 0.8835041938490215\n",
      "(Theirs) Test accuracy: 0.791023842917251\n",
      "******************************\n",
      "(Ours) Runtime: 23.08477210998535\n",
      "(Theirs) Runtime: 25.917784690856934\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8499534016775396\n",
      "(Ours) Test accuracy: 0.7405329593267882\n",
      "(Theirs) Train accuracy: 0.875116495806151\n",
      "(Theirs) Test accuracy: 0.791023842917251\n",
      "******************************\n",
      "(Ours) Runtime: 19.895964860916138\n",
      "(Theirs) Runtime: 23.8307888507843\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8564771668219944\n",
      "(Ours) Test accuracy: 0.7391304347826086\n",
      "(Theirs) Train accuracy: 0.8760484622553588\n",
      "(Theirs) Test accuracy: 0.7966339410939691\n",
      "******************************\n",
      "(Ours) Runtime: 20.44783306121826\n",
      "(Theirs) Runtime: 22.53705072402954\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8676607642124884\n",
      "(Ours) Test accuracy: 0.7840112201963534\n",
      "(Theirs) Train accuracy: 0.8602050326188257\n",
      "(Theirs) Test accuracy: 0.7685834502103787\n",
      "******************************\n",
      "(Ours) Runtime: 22.087934017181396\n",
      "(Theirs) Runtime: 21.949432134628296\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8322460391425909\n",
      "(Ours) Test accuracy: 0.7573632538569425\n",
      "(Theirs) Train accuracy: 0.8760484622553588\n",
      "(Theirs) Test accuracy: 0.7363253856942497\n",
      "******************************\n",
      "(Ours) Runtime: 19.555191040039062\n",
      "(Theirs) Runtime: 21.739092111587524\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8620689655172413\n",
      "(Ours) Test accuracy: 0.7685834502103787\n",
      "(Theirs) Train accuracy: 0.8685927306616962\n",
      "(Theirs) Test accuracy: 0.7755960729312763\n",
      "******************************\n",
      "(Ours) Runtime: 17.11106514930725\n",
      "(Theirs) Runtime: 21.845423936843872\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 0.8575955265610439,\n",
       " 0.013809466126368275,\n",
       " 0.7622720897615709,\n",
       " 0.016080174797061916,\n",
       " 0.8689655172413794,\n",
       " 0.012209827575144324,\n",
       " 0.7719495091164095,\n",
       " 0.019425850988141116,\n",
       " 20.838464999198912,\n",
       " 2.094346177385369,\n",
       " 23.885877633094786,\n",
       " 1.6506556262047691)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = ng_test.target\n",
    "compare_runtimes(\"HRFC\", pca_train_vecs_huge, pca_train_labels_huge, pca_test_vecs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1f84f0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "\n",
    "mndata = MNIST('mnist/')\n",
    "\n",
    "train_images, train_labels = mndata.load_training()\n",
    "test_images, test_labels = mndata.load_testing()\n",
    "\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "test_images = np.array(test_images)\n",
    "test_labels = np.array(test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3b6fdd1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_images).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ec27e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2z/dxb5rnhd7wx6yg77m3z4c1n40000gn/T/ipykernel_44267/2479672015.py:39: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  our_test_acc = np.mean(our_model.predict_batch(test_data)[0] == test_targets)\n",
      "/var/folders/2z/dxb5rnhd7wx6yg77m3z4c1n40000gn/T/ipykernel_44267/2479672015.py:41: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  their_test_acc = np.mean(their_model.predict_batch(test_data)[0] == test_targets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 0.7571\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7843333333333333\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 63.211597204208374\n",
      "(Theirs) Runtime: 277.41305923461914\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.75775\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7789833333333334\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 64.38117504119873\n",
      "(Theirs) Runtime: 257.7257170677185\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7639\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.75385\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 61.45366072654724\n",
      "(Theirs) Runtime: 222.81906414031982\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7476666666666667\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7629666666666667\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 57.80263113975525\n",
      "(Theirs) Runtime: 220.82625699043274\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7718666666666667\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7719833333333334\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 54.77347683906555\n",
      "(Theirs) Runtime: 227.3582911491394\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7646666666666667\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7576333333333334\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 51.59064817428589\n",
      "(Theirs) Runtime: 217.1352949142456\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7571\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7656\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 51.49304819107056\n",
      "(Theirs) Runtime: 216.4136199951172\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7624666666666666\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.74835\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 53.94985604286194\n",
      "(Theirs) Runtime: 216.2584729194641\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7652666666666667\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7613666666666666\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 50.04034900665283\n",
      "(Theirs) Runtime: 210.312518119812\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.76185\n",
      "(Ours) Test accuracy: 0.0\n",
      "(Theirs) Train accuracy: 0.7633\n",
      "(Theirs) Test accuracy: 0.0\n",
      "******************************\n",
      "(Ours) Runtime: 51.11007809638977\n",
      "(Theirs) Runtime: 213.75734615325928\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 0.7609633333333333,\n",
       " 0.006162497689880117,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.7648366666666666,\n",
       " 0.010460448790032337,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 55.980652046203616,\n",
       " 5.100300028883073,\n",
       " 228.00196406841278,\n",
       " 20.760141606448816)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_runtimes(\"HRFC\", train_images, train_labels, test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "796002f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC_sklearn\n",
    "rfc = RFC_sklearn()\n",
    "rfc.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca7a08cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rfc.predict(test_images) == test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbdced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
