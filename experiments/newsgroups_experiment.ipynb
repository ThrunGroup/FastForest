{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592af781",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5de16cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.datasets import *\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import copy\n",
    "\n",
    "from data_structures.tree_classifier import TreeClassifier\n",
    "import utils.utils\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58a183e",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331e630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all datasets from sklearn\n",
    "for m in [fetch_olivetti_faces, fetch_20newsgroups_vectorized, fetch_lfw_people, fetch_lfw_pairs, fetch_covtype, fetch_rcv1, fetch_kddcup99, fetch_california_housing]:\n",
    "    print(m)\n",
    "    try:\n",
    "        all_ = m()\n",
    "        train = m(subset='train')\n",
    "        test = m(subset='test')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dea93964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datapoints:  1073\n",
      "Number of features:  18217\n",
      "Balance:  0.5526561043802423\n"
     ]
    }
   ],
   "source": [
    "# Download the data from two categories\n",
    "cats = ['alt.atheism', 'sci.space']\n",
    "ng_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "ng_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), categories=cats)\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "trans = vectorizer.fit(ng_train.data)\n",
    "train_vectors = vectorizer.transform(ng_train.data)\n",
    "test_vectors = vectorizer.transform(ng_test.data)\n",
    "print(\"Number of datapoints: \", len(ng_train.data))\n",
    "print(\"Number of features: \", train_vectors.shape[1])\n",
    "print(\"Balance: \", np.sum(ng_train.target) / len(ng_train.target)) # 55-45, roughly balanced\n",
    "\n",
    "N_COMPONENTS=100\n",
    "pca = PCA(n_components=N_COMPONENTS)\n",
    "pca.fit(train_vectors.toarray())\n",
    "pca_train_vecs = pca.transform(train_vectors.toarray())\n",
    "pca_test_vecs = pca.transform(test_vectors.toarray())\n",
    "\n",
    "classes_arr = np.unique(ng_train.target)\n",
    "classes = utils.utils.class_to_idx(classes_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19da9b97",
   "metadata": {},
   "source": [
    "# Compare our implementation's accuracy to sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "983ecf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Decision Tree Accuracy: 0.7812061711079944\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=0)\n",
    "dt.fit(pca_train_vecs,ng_train.target)\n",
    "print(\"sklearn Decision Tree Accuracy:\", np.mean(dt.predict(pca_test_vecs) == ng_test.target))\n",
    "\n",
    "#cross_val_score(dt, pca_train_vecs, ng_train.target, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2554a668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Random Forest Accuracy: 0.8022440392706872\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(pca_train_vecs,ng_train.target)\n",
    "print(\"sklearn Random Forest Accuracy:\", np.mean(rf.predict(pca_test_vecs) == ng_test.target))\n",
    "\n",
    "#cross_val_score(rf, pca_train_vecs, ng_train.target, cv=10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a84470d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9086672879776329\n",
      "Test accuracy: 0.7812061711079944\n",
      "Num queries: 5271\n",
      "Runtime: 21.913602113723755\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs, labels=ng_train.target, max_depth=5, classes=classes, verbose=False)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee840a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9086672879776329\n",
      "Test accuracy: 0.7812061711079944\n",
      "Num queries: 5344\n",
      "Runtime: 12.790964126586914\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs, labels=ng_train.target, max_depth=5, classes=classes, solver=\"EXACT\", verbose=False)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ffd149",
   "metadata": {},
   "source": [
    "# Make the dataset huge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "877237a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1073, 100)\n",
      "(17168, 100)\n"
     ]
    }
   ],
   "source": [
    "doublings = 4\n",
    "pca_train_vecs_huge = copy.deepcopy(pca_train_vecs)\n",
    "pca_train_labels_huge = copy.deepcopy(ng_train.target)\n",
    "print(pca_train_vecs_huge.shape)\n",
    "for i in range(doublings):\n",
    "    pca_train_vecs_huge = np.concatenate((pca_train_vecs_huge, pca_train_vecs_huge))\n",
    "    pca_train_labels_huge = np.concatenate((pca_train_labels_huge, pca_train_labels_huge))\n",
    "print(pca_train_vecs_huge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8eca539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated split with 6600 queries\n",
      "Calculated split with 6576 queries\n",
      "Calculated split with 8500 queries\n",
      "Fitting finished\n",
      "Train accuracy: 0.7996272134203168\n",
      "Test accuracy: 0.7531556802244039\n",
      "Num queries: 21676\n",
      "Runtime: 12.382985830307007\n",
      "|--- feature_1 <= -0.02424286634709316\n",
      "|   |--- feature_18 <= 0.028246263503167335\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_18 > 0.028246263503167335\n",
      "|   |   |--- class: 0\n",
      "|--- feature_1 > -0.02424286634709316\n",
      "|   |--- feature_3 <= -0.016323886201712157\n",
      "|   |   |--- class: 1\n",
      "|   |--- feature_3 > -0.016323886201712157\n",
      "|   |   |--- class: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tc = TreeClassifier(data=pca_train_vecs_huge, labels=pca_train_labels_huge, max_depth=2, classes=classes, verbose=True, random_state=0)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)\n",
    "tc.tree_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58f5a946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated split with 17168 queries\n",
      "Calculated split with 6576 queries\n",
      "Calculated split with 10592 queries\n",
      "Fitting finished\n",
      "Train accuracy: 0.7996272134203168\n",
      "Test accuracy: 0.7531556802244039\n",
      "Num queries: 34336\n",
      "Runtime: 21.095016956329346\n",
      "|--- feature_1 <= -0.02424286634709316\n",
      "|   |--- feature_18 <= 0.028246263503167335\n",
      "|   |   |--- class: 0\n",
      "|   |--- feature_18 > 0.028246263503167335\n",
      "|   |   |--- class: 0\n",
      "|--- feature_1 > -0.02424286634709316\n",
      "|   |--- feature_3 <= -0.016323886201712157\n",
      "|   |   |--- class: 1\n",
      "|   |--- feature_3 > -0.016323886201712157\n",
      "|   |   |--- class: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We should implement vanilla TreeClassifier --> which uses identity bins\n",
    "\n",
    "tc = TreeClassifier(data=pca_train_vecs_huge, labels=pca_train_labels_huge, max_depth=2, classes=classes, solver=\"EXACT\", verbose=True, random_state=0)\n",
    "start = time.time()\n",
    "tc.fit()\n",
    "end = time.time()\n",
    "print(\"Train accuracy:\", np.mean(tc.predict_batch(pca_train_vecs)[0] == ng_train.target))\n",
    "print(\"Test accuracy:\", np.mean(tc.predict_batch(pca_test_vecs)[0] == ng_test.target))\n",
    "print(\"Num queries:\", tc.num_queries)\n",
    "print(\"Runtime:\", end-start)\n",
    "tc.tree_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdec262c",
   "metadata": {},
   "source": [
    "# Verify our implementation of baseline models agrees with sklearn's in terms of accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264ead3d",
   "metadata": {},
   "source": [
    "# Classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d76ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_structures.wrappers.random_forest_classifier import RandomForestClassifier as RFC_ours\n",
    "from data_structures.wrappers.extremely_random_forest_classifier import ExtremelyRandomForestClassifier as ERFC_ours\n",
    "\n",
    "from data_structures.wrappers.random_forest_regressor import RandomForestRegressor as RFR_ours\n",
    "from data_structures.wrappers.extremely_random_forest_regressor import ExtremelyRandomForestRegressor as ERFR_ours\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC_sklearn\n",
    "from sklearn.ensemble import ExtraTreesClassifier as ERFC_sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR_sklearn\n",
    "from sklearn.ensemble import ExtraTreesRegressor as ERFR_sklearn\n",
    "\n",
    "from utils.constants import GINI, BEST, EXACT, MSE\n",
    "\n",
    "# TODO(@motiwari): Allow for gradient boosted comparisons as well\n",
    "def compare_accuracies(\n",
    "    compare: str = \"RFC\",\n",
    "    train_data: np.ndarray = None,\n",
    "    train_targets: np.ndarray = None,\n",
    "    test_data: np.ndarray = None,\n",
    "    test_targets: np.ndarray = None,\n",
    "    num_seeds: int = 10,\n",
    ") -> bool:\n",
    "    our_train_accs = []\n",
    "    our_test_accs = []\n",
    "    their_train_accs = []\n",
    "    their_test_accs = []\n",
    "    for seed in range(num_seeds):\n",
    "        # Ok to have n_jobs = -1 throughout?\n",
    "        if compare == \"RFC\":\n",
    "            our_model = RFC_ours(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = RFC_sklearn(n_estimators=5, criterion='gini', max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        elif compare == \"ERFC\":\n",
    "            our_model = ERFC_ours(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, num_bins=None, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = ERFC_sklearn(n_estimators=5, criterion='gini', max_depth=5, min_samples_split=2, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=False, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        elif compare == \"RFR\":\n",
    "            our_model = RFR_ours(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=MSE, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = RFR_sklearn(n_estimators=5, criterion='squared_error', max_depth=5, min_samples_split=2, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, n_jobs=-1, random_state=seed, verbose=0)    \n",
    "        elif compare == \"ERFR\":\n",
    "            our_model = ERFR_ours(data=train_data, labels=train_targets, n_estimators=5, max_depth=5, num_bins=None, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=MSE, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "            their_model = ERFR_sklearn(n_estimators=5, criterion='squared_error', max_depth=5, min_samples_split=2, max_features='auto', min_impurity_decrease=0.0, bootstrap=False, n_jobs=-1, random_state=seed, verbose=0)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Need to decide what models to compare\")\n",
    "        \n",
    "        our_model.fit()\n",
    "        their_model.fit(train_data, train_targets)\n",
    "\n",
    "        if compare == \"RFC\" or compare == \"ERFC\" or compare == \"HRFC\":\n",
    "            our_train_acc = np.mean(our_model.predict_batch(train_data)[0] == train_targets)\n",
    "            our_test_acc = np.mean(our_model.predict_batch(test_data)[0] == test_targets)\n",
    "            their_train_acc = np.mean(their_model.predict(train_data) == train_targets)\n",
    "            their_test_acc = np.mean(their_model.predict(test_data) == test_targets)\n",
    "        elif compare == \"RFR\" or compare == \"ERFR\" or compare == \"HRFR\":\n",
    "            our_train_acc = np.mean((our_model.predict_batch(train_data) - train_targets)**2)\n",
    "            our_test_acc = np.mean((our_model.predict_batch(test_data) - test_targets)**2)\n",
    "            their_train_acc = np.mean((our_model.predict_batch(train_data) - train_targets)**2)\n",
    "            their_test_acc = np.mean((our_model.predict_batch(test_data) - test_targets)**2)\n",
    "\n",
    "        print(\"(Ours) Train accuracy:\", our_train_acc)\n",
    "        print(\"(Ours) Test accuracy:\", our_test_acc)\n",
    "        print(\"(Theirs) Train accuracy:\", their_train_acc)\n",
    "        print(\"(Theirs) Test accuracy:\", their_test_acc)\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        our_train_accs.append(our_train_acc)\n",
    "        our_test_accs.append(our_test_acc)\n",
    "        their_train_accs.append(their_train_acc)\n",
    "        their_test_accs.append(their_test_acc)\n",
    "    \n",
    "    our_avg_train = np.mean(our_train_accs)\n",
    "    our_std_train = np.std(our_train_accs)\n",
    "\n",
    "    our_avg_test = np.mean(our_test_accs)\n",
    "    our_std_test = np.std(our_test_accs)\n",
    "    \n",
    "    their_avg_train = np.mean(their_train_accs)\n",
    "    their_std_train = np.std(their_train_accs)\n",
    "    \n",
    "    their_avg_test = np.mean(their_test_accs)\n",
    "    their_std_test = np.std(their_test_accs)\n",
    "    \n",
    "    # See if confidence intervals overlap\n",
    "    overlap = np.abs(their_avg_test - our_avg_test) < their_std_test + our_std_test\n",
    "    return overlap, our_avg_train, our_std_train, our_avg_test, our_std_test, their_avg_train, their_std_train, their_avg_test, their_std_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d3ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pca_train_vecs\n",
    "train_labels = ng_train.target\n",
    "test_data = pca_test_vecs\n",
    "test_labels = ng_test.target\n",
    "\n",
    "compare_accuracies(\"RFC\", train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd52dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_accuracies(\"ERFC\", train_data, train_labels, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a81cc33",
   "metadata": {},
   "source": [
    "# Regression: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2065315",
   "metadata": {},
   "source": [
    "### Weirdly, we get exactly the same results as sklearn for all seeds. We should investigate whether this is a bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c4cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "data, targets = fetch_california_housing(return_X_y=True)\n",
    "random_idcs = np.random.choice(len(data), size=len(data),replace=False)\n",
    "data = data[random_idcs]\n",
    "targets = targets[random_idcs]\n",
    "\n",
    "TRAIN_TEST_SPLIT = 16000\n",
    "train_data = data[:TRAIN_TEST_SPLIT]\n",
    "train_targets = targets[:TRAIN_TEST_SPLIT]\n",
    "\n",
    "test_data = data[TRAIN_TEST_SPLIT:]\n",
    "test_targets = targets[TRAIN_TEST_SPLIT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf5a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_accuracies(\"RFR\", train_data, train_targets, test_data, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159edac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_accuracies(\"ERFR\", train_data, train_targets, test_data, test_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93283362",
   "metadata": {},
   "source": [
    "# Verify MAB solvers are faster in speed but have no change in accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a826b",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "934b6431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from typing import Any, Tuple\n",
    "\n",
    "# Classification #\n",
    "# Vanilla random forest + H + GB + GBH\n",
    "from data_structures.wrappers.random_forest_classifier import RandomForestClassifier as RFC\n",
    "from data_structures.wrappers.histogram_random_forest_classifier import HistogramRandomForestClassifier as HRFC\n",
    "from data_structures.wrappers.gradient_boosted_random_forest_classifier import GradientBoostedRandomForestClassifier as GBRFC\n",
    "from data_structures.wrappers.gradient_boosted_histogram_random_forest_classifier import GradientBoostedHistogramRandomForestClassifier as GBHRFC\n",
    "\n",
    "# Extremely random forest + GB (already histogrammed)\n",
    "from data_structures.wrappers.extremely_random_forest_classifier import ExtremelyRandomForestClassifier as ERFC\n",
    "from data_structures.wrappers.gradient_boosted_extremely_random_forest_classifier import GradientBoostedExtremelyRandomForestClassifier as GBERFC\n",
    "\n",
    "# Random patches + H + GB + GBH\n",
    "from data_structures.wrappers.random_patches_classifier import RandomPatchesClassifier as RPC\n",
    "from data_structures.wrappers.histogram_random_patches_classifier import HistogramRandomPatchesClassifier as HRPC\n",
    "from data_structures.wrappers.gradient_boosted_random_patches_classifier import GradientBoostedRandomPatchesClassifier as GBRPC\n",
    "from data_structures.wrappers.histogram_random_patches_classifier import HistogramRandomPatchesClassifier as HBRPC\n",
    "\n",
    "\n",
    "# Regression #\n",
    "# Vanilla random forest + H + GB + GBH\n",
    "from data_structures.wrappers.random_forest_regressor import RandomForestRegressor as RFR\n",
    "from data_structures.wrappers.histogram_random_forest_regressor import HistogramRandomForestRegressor as HRFR\n",
    "from data_structures.wrappers.gradient_boosted_random_forest_regressor import GradientBoostedRandomForestRegressor as GBRFR\n",
    "from data_structures.wrappers.gradient_boosted_histogram_random_forest_regressor import GradientBoostedHistogramRandomForestRegressor as GBHRFR\n",
    "\n",
    "# Extremely random forest + GB (already histogrammed)\n",
    "from data_structures.wrappers.extremely_random_forest_regressor import ExtremelyRandomForestRegressor as ERFR\n",
    "from data_structures.wrappers.gradient_boosted_extremely_random_forest_regressor import GradientBoostedExtremelyRandomForestRegressor as GBERFR\n",
    "\n",
    "# Random patches + H + GB + GBH\n",
    "from data_structures.wrappers.random_patches_regressor import RandomPatchesRegressor as RPR\n",
    "from data_structures.wrappers.histogram_random_patches_regressor import HistogramRandomPatchesRegressor as HRPR\n",
    "from data_structures.wrappers.gradient_boosted_random_patches_regressor import GradientBoostedRandomPatchesRegressor as GBRPR\n",
    "from data_structures.wrappers.histogram_random_patches_regressor import HistogramRandomPatchesRegressor as HBRPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1638e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_measured_fit(\n",
    "    model: Any,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Returns wall clock time of training the model, in seconds.\n",
    "    \n",
    "    Has a side effect: trains the model.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    model.fit()\n",
    "    end = time.time()\n",
    "    return end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe207c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.constants import GINI, BEST, EXACT, MAB, MSE\n",
    "\n",
    "\n",
    "def compare_runtimes(\n",
    "    compare: str = \"HRFC\",\n",
    "    train_data: np.ndarray = None,\n",
    "    train_targets: np.ndarray = None,\n",
    "    test_data: np.ndarray = None,\n",
    "    test_targets: np.ndarray = None,\n",
    "    num_seeds: int = 10,\n",
    ") -> bool:\n",
    "    # Runtimes\n",
    "    our_train_times = []\n",
    "    their_train_times = []\n",
    "    \n",
    "    # For accuracies\n",
    "    our_train_accs = []\n",
    "    our_test_accs = []\n",
    "    their_train_accs = []\n",
    "    their_test_accs = []\n",
    "    for seed in range(num_seeds):\n",
    "        # Ok to have n_jobs = -1 throughout?\n",
    "        if compare == \"HRFC\":\n",
    "            our_model = HRFC(data=train_data, labels=train_targets, n_estimators=1, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=MAB, random_state=seed, verbose=False)\n",
    "            their_model = HRFC(data=train_data, labels=train_targets, n_estimators=1, max_depth=5, min_samples_split=2, min_impurity_decrease=0, max_leaf_nodes=None, budget=None, criterion=GINI, splitter=BEST, solver=EXACT, random_state=seed, verbose=False)\n",
    "        else:\n",
    "            raise NotImplementedError(\"Need to decide what models to compare\")\n",
    "        \n",
    "        assert 'sklearn' not in their_model.__module__, \"Cannot use sklearn models for runtime comparisons\"\n",
    "        \n",
    "        our_runtime = time_measured_fit(our_model)\n",
    "        our_train_times.append(our_runtime)\n",
    "\n",
    "        their_runtime = time_measured_fit(their_model)\n",
    "        their_train_times.append(their_runtime)\n",
    "\n",
    "        if compare == \"RFC\" or compare == \"ERFC\" or compare == \"HRFC\":\n",
    "            our_train_acc = np.mean(our_model.predict_batch(train_data)[0] == train_targets)\n",
    "            our_test_acc = np.mean(our_model.predict_batch(test_data)[0] == test_targets)\n",
    "            their_train_acc = np.mean(their_model.predict_batch(train_data)[0] == train_targets)\n",
    "            their_test_acc = np.mean(their_model.predict_batch(test_data)[0] == test_targets)\n",
    "\n",
    "        print(\"(Ours) Train accuracy:\", our_train_acc)\n",
    "        print(\"(Ours) Test accuracy:\", our_test_acc)\n",
    "        print(\"(Theirs) Train accuracy:\", their_train_acc)\n",
    "        print(\"(Theirs) Test accuracy:\", their_test_acc)\n",
    "        print(\"*\" * 30)\n",
    "        print(\"(Ours) Runtime:\", our_runtime)\n",
    "        print(\"(Theirs) Runtime:\", their_runtime)\n",
    "        print(\"-\" * 30)\n",
    "\n",
    "        our_train_accs.append(our_train_acc)\n",
    "        our_test_accs.append(our_test_acc)\n",
    "        their_train_accs.append(their_train_acc)\n",
    "        their_test_accs.append(their_test_acc)\n",
    "    \n",
    "    # For accuracies\n",
    "    our_avg_train = np.mean(our_train_accs)\n",
    "    our_std_train = np.std(our_train_accs)\n",
    "\n",
    "    our_avg_test = np.mean(our_test_accs)\n",
    "    our_std_test = np.std(our_test_accs)\n",
    "    \n",
    "    their_avg_train = np.mean(their_train_accs)\n",
    "    their_std_train = np.std(their_train_accs)\n",
    "    \n",
    "    their_avg_test = np.mean(their_test_accs)\n",
    "    their_std_test = np.std(their_test_accs)\n",
    "    \n",
    "    # For runtimes\n",
    "    our_avg_train_time = np.mean(our_train_times)\n",
    "    our_std_train_time = np.std(our_train_times)\n",
    "    \n",
    "    their_avg_train_time = np.mean(their_train_times)\n",
    "    their_std_train_time = np.std(their_train_times)\n",
    "    \n",
    "    \n",
    "    # See if confidence intervals overlap\n",
    "    overlap = np.abs(their_avg_test - our_avg_test) < their_std_test + our_std_test\n",
    "    return overlap, our_avg_train, our_std_train, our_avg_test, our_std_test, their_avg_train, their_std_train, their_avg_test, their_std_test, our_avg_train_time, our_std_train_time, their_avg_train_time, their_std_train_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc8bf776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Ours) Train accuracy: 0.7949673811742777\n",
      "(Ours) Test accuracy: 0.7279102384291725\n",
      "(Theirs) Train accuracy: 0.6514445479962722\n",
      "(Theirs) Test accuracy: 0.5988779803646563\n",
      "******************************\n",
      "(Ours) Runtime: 4.293490886688232\n",
      "(Theirs) Runtime: 4.669025897979736\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8313140726933831\n",
      "(Ours) Test accuracy: 0.7643758765778401\n",
      "(Theirs) Train accuracy: 0.7260018639328985\n",
      "(Theirs) Test accuracy: 0.6297335203366059\n",
      "******************************\n",
      "(Ours) Runtime: 6.979787111282349\n",
      "(Theirs) Runtime: 4.930572748184204\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6971109040074557\n",
      "(Ours) Test accuracy: 0.6255259467040674\n",
      "(Theirs) Train accuracy: 0.798695246971109\n",
      "(Theirs) Test accuracy: 0.7503506311360448\n",
      "******************************\n",
      "(Ours) Runtime: 2.8953399658203125\n",
      "(Theirs) Runtime: 4.9914870262146\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6915191053122087\n",
      "(Ours) Test accuracy: 0.6016830294530154\n",
      "(Theirs) Train accuracy: 0.7623485554520038\n",
      "(Theirs) Test accuracy: 0.6816269284712483\n",
      "******************************\n",
      "(Ours) Runtime: 3.8308091163635254\n",
      "(Theirs) Runtime: 5.03103494644165\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.7548928238583411\n",
      "(Ours) Test accuracy: 0.7040673211781207\n",
      "(Theirs) Train accuracy: 0.684995340167754\n",
      "(Theirs) Test accuracy: 0.6465638148667602\n",
      "******************************\n",
      "(Ours) Runtime: 3.2068839073181152\n",
      "(Theirs) Runtime: 5.079509019851685\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6570363466915191\n",
      "(Ours) Test accuracy: 0.6002805049088359\n",
      "(Theirs) Train accuracy: 0.7101584342963654\n",
      "(Theirs) Test accuracy: 0.6283309957924264\n",
      "******************************\n",
      "(Ours) Runtime: 3.9353132247924805\n",
      "(Theirs) Runtime: 4.868818998336792\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6812674743709226\n",
      "(Ours) Test accuracy: 0.6115007012622721\n",
      "(Theirs) Train accuracy: 0.7847157502329916\n",
      "(Theirs) Test accuracy: 0.699859747545582\n",
      "******************************\n",
      "(Ours) Runtime: 3.0580368041992188\n",
      "(Theirs) Runtime: 5.0093419551849365\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6952469711090401\n",
      "(Ours) Test accuracy: 0.6605890603085554\n",
      "(Theirs) Train accuracy: 0.8126747437092264\n",
      "(Theirs) Test accuracy: 0.7349228611500701\n",
      "******************************\n",
      "(Ours) Runtime: 3.3299379348754883\n",
      "(Theirs) Runtime: 4.9959189891815186\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.8108108108108109\n",
      "(Ours) Test accuracy: 0.7503506311360448\n",
      "(Theirs) Train accuracy: 0.7036346691519105\n",
      "(Theirs) Test accuracy: 0.6577840112201964\n",
      "******************************\n",
      "(Ours) Runtime: 5.997798919677734\n",
      "(Theirs) Runtime: 4.928012132644653\n",
      "------------------------------\n",
      "(Ours) Train accuracy: 0.6924510717614166\n",
      "(Ours) Test accuracy: 0.6283309957924264\n",
      "(Theirs) Train accuracy: 0.8238583410997204\n",
      "(Theirs) Test accuracy: 0.7545582047685835\n",
      "******************************\n",
      "(Ours) Runtime: 3.8661880493164062\n",
      "(Theirs) Runtime: 4.864493131637573\n",
      "------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " 0.7306616961789375,\n",
       " 0.0587449436343466,\n",
       " 0.667461430575035,\n",
       " 0.060469630618275004,\n",
       " 0.7458527493010252,\n",
       " 0.05584967868807881,\n",
       " 0.6782608695652175,\n",
       " 0.05223043583543516,\n",
       " 4.139358592033386,\n",
       " 1.2648541739642905,\n",
       " 4.936821484565735,\n",
       " 0.11075324854478229)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels = ng_test.target\n",
    "compare_runtimes(\"HRFC\", pca_train_vecs_huge, pca_train_labels_huge, pca_test_vecs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1308f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
